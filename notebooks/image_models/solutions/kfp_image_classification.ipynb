{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2a8dc6-d334-42fc-ae90-005d5bc2fea0",
   "metadata": {},
   "source": [
    "# Custom Image Models with Kubeflow Pipeline and Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac9c9ba-0d0a-4237-9fb7-3afd93f24ba4",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "1. Learn how to use Kubeflow pre-built components\n",
    "1. Learn how to build a Kubeflow pipeline with these components\n",
    "1. Learn how to compile, upload, and run a Kubeflow pipeline\n",
    "\n",
    "\n",
    "In this lab, you will build, deploy, and execute a Kubeflow pipeline that orchestrates the Vertex AI services to train and deploy a simple custom image classification model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8cd358-9870-4a90-b5f0-a9162def36fe",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a982b6b-e884-4055-897a-0038704b1328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUCKET=kylesteckler-instructor-flowers\n",
      "env: PROJECT=kylesteckler-instructor\n",
      "env: REGION=us-central1\n",
      "env: ARTIFACT_STORE=gs://kylesteckler-instructor-flowers-kfp-artifact-store\n"
     ]
    }
   ],
   "source": [
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT + \"-flowers\"\n",
    "TRAIN_DATA_PATH = f\"gs://{BUCKET}/data/train*\"\n",
    "EVAL_DATA_PATH = f\"gs://{BUCKET}/data/eval*\"\n",
    "REGION = \"us-central1\"\n",
    "ARTIFACT_STORE = f\"gs://{BUCKET}-kfp-artifact-store\"\n",
    "\n",
    "%env BUCKET={BUCKET}\n",
    "%env PROJECT={PROJECT}\n",
    "%env REGION={REGION}\n",
    "%env ARTIFACT_STORE={ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7139ced-9eab-4d22-a9f6-12be78119687",
   "metadata": {},
   "source": [
    "### Data \n",
    "Create the bucket and copy the data neccesary for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11698d1-4718-4590-95b4-d94707dff6aa",
   "metadata": {},
   "source": [
    "First, create the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e181b4ab-92be-4d83-9b25-facd274fcfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket gs://kylesteckler-instructor-flowers already exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "  echo -e \"Bucket gs://${BUCKET} already exists.\"\n",
    "    \n",
    "else\n",
    "   echo \"Creating a new GCS bucket.\"\n",
    "   gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "   echo -e \"\\nHere are your current buckets:\"\n",
    "   gsutil ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f094ef7-09bf-43d9-85aa-daec1abb1253",
   "metadata": {},
   "source": [
    "Copy the data to your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f847ecb1-1b83-40bf-8b71-20f2683e5687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://asl-public/data/flowers/tfrecords/eval.tfrecord-00000-of-00003 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/eval.tfrecord-00001-of-00003 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/eval.tfrecord-00002-of-00003 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00007-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00003-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00002-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00008-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00000-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00004-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00009-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00005-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00001-of-00010 [Content-Type=application/octet-stream]...\n",
      "Copying gs://asl-public/data/flowers/tfrecords/train.tfrecord-00006-of-00010 [Content-Type=application/octet-stream]...\n",
      "/ [13/13 files][159.7 MiB/159.7 MiB] 100% Done                                  \n",
      "Operation completed over 13 objects/159.7 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp gs://asl-public/data/flowers/tfrecords/* gs://{BUCKET}/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b607b-d4fe-4b8b-b40c-ee5197992a15",
   "metadata": {},
   "source": [
    "Make sure the data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab62d2b-22b6-4065-9a44-d212b1ee4ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00000-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00001-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00002-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00003-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00004-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00005-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00006-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00007-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00008-of-00010\n",
      "gs://kylesteckler-instructor-flowers/data/train.tfrecord-00009-of-00010\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {TRAIN_DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d85080-5c69-4f48-a740-0a7b804322a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kylesteckler-instructor-flowers/data/eval.tfrecord-00000-of-00003\n",
      "gs://kylesteckler-instructor-flowers/data/eval.tfrecord-00001-of-00003\n",
      "gs://kylesteckler-instructor-flowers/data/eval.tfrecord-00002-of-00003\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {EVAL_DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66a382-a8bd-4938-9bd7-ba7d47792a56",
   "metadata": {},
   "source": [
    "### Create Containerized Training Application\n",
    "* Create a Tensorflow training application for image classification\n",
    "* Create a Dockerfile \n",
    "* Build and push training application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb61c99-6618-4880-bffc-be6d046e2a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./flower_trainer’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./flower_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421da64c-7256-449a-a518-6717e1e09333",
   "metadata": {},
   "source": [
    "Create `train.py`, a Python script that builds and trains a Tensorflow/Keras model for image classification on the flowers dataset. This training application leverages a [pre-trained TF Hub model](https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4) as a feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6f8b22-dcde-4220-9375-a3be4b5b6a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./flower_trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./flower_trainer/train.py\n",
    "\n",
    "import tensorflow as tf \n",
    "import fire \n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "\n",
    "AIP_MODEL_DIR = os.environ[\"AIP_MODEL_DIR\"]\n",
    "\n",
    "def parse_example(example, img_shape):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    img = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    \n",
    "    # resize and scale\n",
    "    return tf.image.resize(img, img_shape[:-1])/255.0, example[\"label\"]\n",
    "\n",
    "def create_dataset(pattern, batch_size, img_shape, mode='train'):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    filenames = tf.io.gfile.glob(pattern) # List of files matching pattern\n",
    "    ds = tf.data.TFRecordDataset(filenames)\n",
    "    ds = ds.map(lambda x: parse_example(x, img_shape=img_shape), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Configure for performance\n",
    "    ds = ds.cache()\n",
    "    if mode=='train':\n",
    "        ds = ds.shuffle(buffer_size=10*batch_size).repeat()\n",
    "    else:\n",
    "        ds = ds.repeat(1)\n",
    "    \n",
    "    return ds.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "def build_hub_model(\n",
    "    input_shape,\n",
    "    dense_units,\n",
    "    dropout,\n",
    "    num_classes,\n",
    "    module_handle\n",
    "):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=input_shape) # [height, width, channels]\n",
    "    \n",
    "    # Pre-trained model from tfhub \n",
    "    # trainable=False means frozen weights \n",
    "    hub_layer = hub.KerasLayer(module_handle, trainable=False)(inputs)\n",
    "    \n",
    "    # Additional learned dense layer \n",
    "    dense_layer = tf.keras.layers.Dense(dense_units, activation=\"relu\")(hub_layer)\n",
    "    x = tf.keras.layers.Dropout(dropout)(dense_layer)\n",
    "    \n",
    "    # Output the logits \n",
    "    output = tf.keras.layers.Dense(num_classes)(x)\n",
    "    \n",
    "    # Instantiate keras model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return model \n",
    "    \n",
    "\n",
    "def train_evaluate(\n",
    "    train_data_path,\n",
    "    eval_data_path,\n",
    "    batch_size,\n",
    "    num_steps,\n",
    "    num_evals,\n",
    "    img_shape=[224,224,3],\n",
    "    dense_units=16,\n",
    "    dropout=0.1,\n",
    "    num_classes=5,\n",
    "    module_handle=\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "):\n",
    "    \n",
    "    train_ds = create_dataset(train_data_path, batch_size=batch_size, img_shape=img_shape)\n",
    "    val_ds = create_dataset(eval_data_path, batch_size=64, img_shape=img_shape,mode='test')\n",
    "\n",
    "    steps_per_epoch = num_steps // (num_evals * batch_size)\n",
    "    \n",
    "    # Build model \n",
    "    model = build_hub_model(\n",
    "        input_shape=img_shape,\n",
    "        dense_units=dense_units,\n",
    "        dropout=dropout,\n",
    "        num_classes=num_classes,\n",
    "        module_handle=module_handle\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=num_evals,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    model.save(AIP_MODEL_DIR)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fire.Fire(train_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0dddd0-5926-435f-88eb-e862be464105",
   "metadata": {},
   "source": [
    "Create Dockerfile, then build and push your training application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a585b75c-d503-4d15-96e0-f3b058eaca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./flower_trainer/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./flower_trainer/Dockerfile\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-7\n",
    "\n",
    "# Installs hypertune library and fire \n",
    "RUN pip install -U fire\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "WORKDIR /app\n",
    "COPY train.py .\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69aea736-21e7-484c-adc1-e26cee8cd9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/kylesteckler-instructor/flowers_trainer_tf:latest'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_NAME = \"flowers_trainer_tf\"\n",
    "TAG = \"latest\"\n",
    "TRAINING_CONTAINER_IMAGE_URI = f\"gcr.io/{PROJECT}/{IMAGE_NAME}:{TAG}\"\n",
    "TRAINING_CONTAINER_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7f9df-a27c-4143-9c6f-1b99720773b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --machine-type=e2-highcpu-32 --timeout=15m --tag $TRAINING_CONTAINER_IMAGE_URI flower_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611fff8d-e047-4454-9a07-8488d7f9288a",
   "metadata": {},
   "source": [
    "### Kubeflow Pipeline\n",
    "Create a Kubeflow pipeline that leverages Vertex AI services to train and deploy the custom image classification model. Use pre-built components for Vertex AI Training and deploying the trained model to a Vertex AI Endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dfad305-457a-4eb5-ba73-3bb984ee8ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./image_classification_pipeline’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./image_classification_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85a58bd-678c-4322-92c8-41a9d56d0055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./image_classification_pipeline/pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./image_classification_pipeline/pipeline.py\n",
    "\n",
    "import os\n",
    "\n",
    "from google_cloud_pipeline_components.aiplatform import (\n",
    "    EndpointCreateOp,\n",
    "    ModelDeployOp,\n",
    "    ModelUploadOp,\n",
    ")\n",
    "\n",
    "from google_cloud_pipeline_components.experimental.custom_job import (\n",
    "    CustomTrainingJobOp,\n",
    ")\n",
    "\n",
    "from kfp.v2 import dsl\n",
    "\n",
    "PIPELINE_ROOT = os.getenv(\"PIPELINE_ROOT\")\n",
    "PROJECT = os.getenv(\"PROJECT\")\n",
    "REGION = os.getenv(\"REGION\")\n",
    "\n",
    "TRAINING_CONTAINER_IMAGE_URI = os.getenv(\"TRAINING_CONTAINER_IMAGE_URI\")\n",
    "SERVING_CONTAINER_IMAGE_URI = os.getenv(\"SERVING_CONTAINER_IMAGE_URI\")\n",
    "SERVING_MACHINE_TYPE = os.getenv(\"SERVING_MACHINE_TYPE\", \"n1-standard-16\")\n",
    "\n",
    "TRAIN_DATA_PATH = os.getenv(\"TRAIN_DATA_PATH\")\n",
    "EVAL_DATA_PATH = os.getenv(\"EVAL_DATA_PATH\")\n",
    "\n",
    "BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", \"64\"))\n",
    "NUM_STEPS = int(os.getenv(\"NUM_STEPS\", \"10000\"))\n",
    "NUM_EVALS = int(os.getenv(\"NUM_EVALS\", \"10\"))\n",
    "\n",
    "PIPELINE_NAME = os.getenv(\"PIPELINE_NAME\", \"flower-classification\")\n",
    "BASE_OUTPUT_DIR = os.getenv(\"BASE_OUTPUT_DIR\", PIPELINE_ROOT)\n",
    "MODEL_DISPLAY_NAME = os.getenv(\"MODEL_DISPLAY_NAME\", \"flower_classifier\")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    description=\"Kubeflow pipeline that trains and deploys custom image classifier on Vertex AI\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def create_pipeline():\n",
    "    worker_pool_specs = [\n",
    "        {\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": \"n1-standard-16\",\n",
    "                \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "                \"accelerator_count\": 1,\n",
    "            },\n",
    "            \"replica_count\": 1,\n",
    "            \"container_spec\": {\n",
    "                \"image_uri\": TRAINING_CONTAINER_IMAGE_URI,\n",
    "                \"args\": [\n",
    "                    f\"--train_data_path={TRAIN_DATA_PATH}\",\n",
    "                    f\"--eval_data_path={EVAL_DATA_PATH}\",\n",
    "                    f\"--num_steps={NUM_STEPS}\",\n",
    "                    f\"--num_evals={NUM_EVALS}\",\n",
    "                    f\"--batch_size={BATCH_SIZE}\"\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    training_task = CustomTrainingJobOp(\n",
    "        project=PROJECT,\n",
    "        location=REGION,\n",
    "        display_name=f\"{PIPELINE_NAME}-kfp-training-job\",\n",
    "        worker_pool_specs=worker_pool_specs,\n",
    "        base_output_directory=PIPELINE_ROOT,\n",
    "    )\n",
    "    \n",
    "    model_upload_task = ModelUploadOp(\n",
    "        project=PROJECT,\n",
    "        display_name=f\"{PIPELINE_NAME}-kfp-model-upload-job\",\n",
    "        artifact_uri=f\"{PIPELINE_ROOT}/model\",\n",
    "        serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    "    )\n",
    "    model_upload_task.after(training_task)\n",
    "    \n",
    "    endpoint_create_task = EndpointCreateOp(\n",
    "        project=PROJECT,\n",
    "        display_name=f\"{PIPELINE_NAME}-kfp-create-endpoint-job\",\n",
    "    )\n",
    "    endpoint_create_task.after(model_upload_task)\n",
    "    \n",
    "    model_deploy_op = ModelDeployOp(  # pylint: disable=unused-variable\n",
    "        model=model_upload_task.outputs[\"model\"],\n",
    "        endpoint=endpoint_create_task.outputs[\"endpoint\"],\n",
    "        deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "        dedicated_resources_machine_type=SERVING_MACHINE_TYPE,\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84210b-d9fe-4da7-9c30-0f6c75af327b",
   "metadata": {},
   "source": [
    "### Compile the pipeline\n",
    "Before we compile the pipeline, make sure that the `ARTIFACT_STORE` has been created, and create it if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c13b74e-4dc6-45e0-af78-d0f08e8db696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kylesteckler-instructor-flowers-kfp-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ea15d-b5e5-47eb-9904-3d65b7f8250d",
   "metadata": {},
   "source": [
    "Define the environment variables that will be passed to the pipeline compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67cb947f-36d6-49db-a9b8-651ae966f83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_ROOT=gs://kylesteckler-instructor-flowers-kfp-artifact-store/pipeline\n",
      "env: SERVING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\n",
      "env: TRAIN_DATA_PATH=gs://kylesteckler-instructor-flowers/data/train*\n",
      "env: EVAL_DATA_PATH=gs://kylesteckler-instructor-flowers/data/eval*\n",
      "env: TRAINING_CONTAINER_IMAGE_URI=gcr.io/kylesteckler-instructor/flowers_trainer_tf:latest\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_ROOT = f\"{ARTIFACT_STORE}/pipeline\"\n",
    "SERVING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\"\n",
    ")\n",
    "\n",
    "%env PIPELINE_ROOT={PIPELINE_ROOT}\n",
    "%env SERVING_CONTAINER_IMAGE_URI={SERVING_CONTAINER_IMAGE_URI}\n",
    "%env TRAIN_DATA_PATH={TRAIN_DATA_PATH}\n",
    "%env EVAL_DATA_PATH={EVAL_DATA_PATH}\n",
    "%env TRAINING_CONTAINER_IMAGE_URI={TRAINING_CONTAINER_IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8b1c4-f4d2-4d4e-b066-2307822eebf4",
   "metadata": {},
   "source": [
    "Compile the pipeline from the Python file we generated into a JSON description using the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b909a6ea-db9e-4c6e-8e61-0bdcd6da9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_JSON = \"flower_classification_kfp_pipeline.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f357d7ea-e18f-41a6-8d4e-7b6cba78ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "!dsl-compile-v2 --py image_classification_pipeline/pipeline.py --output $PIPELINE_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d114518-df43-4a59-813c-6a188f467254",
   "metadata": {},
   "source": [
    "The result is the pipeline file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585a76e7-8444-490c-8826-303823b67d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"pipelineSpec\": {\n",
      "    \"components\": {\n",
      "      \"comp-custom-training-job\": {\n",
      "        \"executorLabel\": \"exec-custom-training-job\",\n",
      "        \"inputDefinitions\": {\n",
      "          \"parameters\": {\n",
      "            \"base_output_directory\": {\n",
      "              \"type\": \"STRING\"\n",
      "            },\n"
     ]
    }
   ],
   "source": [
    "!head {PIPELINE_JSON}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5fa05-6d12-41fa-a732-ff87834fb7ed",
   "metadata": {},
   "source": [
    "#### Deploy to Vertex AI Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effc5855-cb5b-4545-8719-09eb005fb300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/flower-classification-20221213182108?project=335831560329\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/335831560329/locations/us-central1/pipelineJobs/flower-classification-20221213182108\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT, location=REGION)\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=\"flower-kfp-pipeline\",\n",
    "    template_path=PIPELINE_JSON,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f6c01c-f5ea-485d-ad1c-8b3469c9f57a",
   "metadata": {},
   "source": [
    "Feel free to go to [Vertex AI Pipelines](google.com) to watch the execution of your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30b5d3-148a-4303-85e3-7104c6f17579",
   "metadata": {},
   "source": [
    "Congrats! You have succesfully built and deployed a Kubeflow Pipeline that orchestrates Vertex AI Custom Training, Model Upload, Endpoint Creation, and Model Deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c52d50-cec0-46d7-bca3-42e86b8b746c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "local-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
