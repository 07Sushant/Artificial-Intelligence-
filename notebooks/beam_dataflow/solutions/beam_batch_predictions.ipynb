{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e8d228-b534-40e0-a5e8-68cd335e6a88",
   "metadata": {},
   "source": [
    "## Creating an index of Movie Embeddings at Scale with Apache Beam and Dataflow\n",
    "In this lab you will deploy an Apache Beam pipeline to Dataflow that sends movie overviews  through a pre-trained NLP model to generate embedded representations of their overviews. This lab is a special case of leveraging Apache Beam/Dataflow as a Batch Prediction infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60778759-1f70-42b4-8520-a78c41ec94cc",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018002d1-d072-4d2f-8fdb-27fca661adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT=kylesteckler-demo\n",
      "env: REGION=us-central1\n",
      "env: BUCKET=kylesteckler-demo\n",
      "env: INPUT_FILE=gs://kylesteckler-demo/movies/movies.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "PROJECT = !(gcloud config get-value core/project)\n",
    "PROJECT = PROJECT[0]\n",
    "REGION = \"us-central1\"\n",
    "BUCKET = PROJECT\n",
    "INPUT_FILE = f\"gs://{BUCKET}/movies/movies.csv\"\n",
    "\n",
    "%env PROJECT={PROJECT}\n",
    "%env REGION={REGION}\n",
    "%env BUCKET={BUCKET}\n",
    "%env INPUT_FILE={INPUT_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eccc21-dd71-4ed5-9348-8ae046384673",
   "metadata": {},
   "source": [
    "Make sure you have a GCS bucket that exists and if not create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cdbac3-d370-47eb-9643-d8639d51d346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket gs://kylesteckler-demo already exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "  echo -e \"Bucket gs://${BUCKET} already exists.\"\n",
    "    \n",
    "else\n",
    "   echo \"Creating a new GCS bucket.\"\n",
    "   gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "   echo -e \"\\nHere are your current buckets:\"\n",
    "   gsutil ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067da44-afae-4714-9b4a-03307d16eee6",
   "metadata": {},
   "source": [
    "Copy CSV to your bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6369de-c3ec-4092-937e-2dd8ad10a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://asl-public/data/movie-descriptions/movies.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 10.5 MiB/ 10.5 MiB]                                                \n",
      "Operation completed over 1 objects/10.5 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://asl-public/data/movie-descriptions/movies.csv {INPUT_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ab016c-137b-4924-ac64-439dbe0ff6b9",
   "metadata": {},
   "source": [
    "#### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aea74e7-8de9-4266-882a-f6b80c38aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody Andy's toys live happily in his r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on mistreated and stepped on the women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heat</td>\n",
       "      <td>Obsessive master thief Neil McCauley leads a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34607</th>\n",
       "      <td>Caged Heat 3000</td>\n",
       "      <td>It's the year 3000 AD. The world's most danger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34608</th>\n",
       "      <td>Robin Hood</td>\n",
       "      <td>Yet another version of the classic epic with e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34609</th>\n",
       "      <td>Siglo ng Pagluluwal</td>\n",
       "      <td>An artist struggles to finish his work while a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34610</th>\n",
       "      <td>Betrayal</td>\n",
       "      <td>When one of her hits goes wrong a professional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34611</th>\n",
       "      <td>Queerama</td>\n",
       "      <td>50 years after decriminalisation of homosexual...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34612 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    original_title  \\\n",
       "0                        Toy Story   \n",
       "1                          Jumanji   \n",
       "2                Waiting to Exhale   \n",
       "3      Father of the Bride Part II   \n",
       "4                             Heat   \n",
       "...                            ...   \n",
       "34607              Caged Heat 3000   \n",
       "34608                   Robin Hood   \n",
       "34609          Siglo ng Pagluluwal   \n",
       "34610                     Betrayal   \n",
       "34611                     Queerama   \n",
       "\n",
       "                                                overview  \n",
       "0      Led by Woody Andy's toys live happily in his r...  \n",
       "1      When siblings Judy and Peter discover an encha...  \n",
       "2      Cheated on mistreated and stepped on the women...  \n",
       "3      Just when George Banks has recovered from his ...  \n",
       "4      Obsessive master thief Neil McCauley leads a t...  \n",
       "...                                                  ...  \n",
       "34607  It's the year 3000 AD. The world's most danger...  \n",
       "34608  Yet another version of the classic epic with e...  \n",
       "34609  An artist struggles to finish his work while a...  \n",
       "34610  When one of her hits goes wrong a professional...  \n",
       "34611  50 years after decriminalisation of homosexual...  \n",
       "\n",
       "[34612 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_FILE)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f9999-396c-42cc-ac96-106c2cf46292",
   "metadata": {},
   "source": [
    "As you can see, this CSV file contains about 35000 rows of data. Each row has a movie title `original_title` and a short paragraph description `overview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f7c61f-9766-4b2a-bc37-fd06d7d0fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Toy Story\n",
      "Overview: Led by Woody Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner the duo eventually learns to put aside their differences.\n"
     ]
    }
   ],
   "source": [
    "# Take a look at one example\n",
    "example = df.iloc[0]\n",
    "title = example[0]\n",
    "overview = example[1]\n",
    "\n",
    "print(f\"Title: {title}\\nOverview: {overview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6813d7-baae-48f8-bd92-9d53756579fd",
   "metadata": {},
   "source": [
    "#### Generating Embeddings\n",
    "It is common to create embeddings, or numeric representations of unstructured data. Embeddings are frequently used in recommender systems and for computing similarities. In this lab we will use a pre-trained model to create embeddings for each movie overview. \n",
    "\n",
    "The model we will use is Google's [Universal Sentence Encoder](https://tfhub.dev/google/universal-sentence-encoder/4). The Universal Sentence Encoder encodes text into 512 dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506488a7-b960-4399-86f1-dbb2ddc22595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 21:45:15.024795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-06-27 21:45:15.024951: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-27 21:45:15.024988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (home-depot-asl): /proc/driver/nvidia/version does not exist\n",
      "2022-06-27 21:45:15.025381: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-27 21:45:17.339645: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the model into memory\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256c7bb5-63b6-4711-9294-6929ee334688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview: Led by Woody Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner the duo eventually learns to put aside their differences.\n",
      "Embedding Shape: (512,)\n",
      "Embedding Value: [ 0.06237842 -0.00021261 -0.0321418   0.04211934 -0.03190538 -0.04727348\n",
      " -0.03579684 -0.06527699 -0.01243671 -0.01291869 -0.03203537  0.05493606\n",
      " -0.04103908  0.01471261 -0.03063923 -0.06317661 -0.0466479   0.04065031\n",
      " -0.05278567  0.05723299 -0.01752132 -0.0664015   0.0681255  -0.02964727\n",
      "  0.0051426   0.06729304 -0.03282264 -0.02283403  0.04896601  0.06429423\n",
      " -0.02937895 -0.06723911 -0.05709471 -0.04732318 -0.04401306 -0.03806528\n",
      "  0.02364934  0.03226624  0.01851922 -0.05438095 -0.01259939 -0.03234723\n",
      " -0.00504965 -0.05542825 -0.05961061  0.06569342  0.04169372  0.0305221\n",
      " -0.03209813 -0.05397084  0.06841838 -0.00631814  0.00088382 -0.04680281\n",
      "  0.05728186  0.0501298  -0.03235426  0.04091225  0.0637769   0.02186143\n",
      "  0.06880636 -0.02428689 -0.06880657  0.01236478  0.0594555  -0.02579409\n",
      "  0.03447118 -0.02245607  0.04398767 -0.02244515  0.05725091  0.04033455\n",
      "  0.01818    -0.00382348 -0.05242833 -0.05865094 -0.01320271  0.02778832\n",
      "  0.06710781  0.01371306  0.05083869  0.03653846  0.03656883 -0.05065436\n",
      "  0.03018299 -0.02040659 -0.0464525  -0.03293014 -0.0172355  -0.06628048\n",
      "  0.06421322 -0.0458248   0.03593411 -0.02965045  0.06108181 -0.06566304\n",
      " -0.00898165 -0.01858259  0.06564424  0.03913704 -0.05275502 -0.01657547\n",
      "  0.0353131  -0.01847346  0.0003265   0.06798308 -0.03713008 -0.04847261\n",
      "  0.05867026 -0.01909624 -0.05120389 -0.03682457  0.06307049  0.01995147\n",
      "  0.05530044  0.00071974 -0.06777553  0.03145699 -0.00813244 -0.03784252\n",
      "  0.00119744  0.00595939 -0.01670771 -0.06706572  0.04746046 -0.01530532\n",
      " -0.06414399 -0.06869207  0.01912408  0.05493027 -0.00252825  0.03374093\n",
      "  0.06338656 -0.01217071 -0.04266633 -0.02493196 -0.02627357 -0.06001749\n",
      " -0.00733223 -0.04535468 -0.0179676   0.06683461 -0.05840152  0.02731212\n",
      "  0.05622549 -0.06547322 -0.00273166  0.06718501  0.02413523  0.0156613\n",
      " -0.06586754  0.05116735 -0.0281366   0.06242005 -0.05393291 -0.00272425\n",
      " -0.06765898  0.02228244 -0.06488561 -0.06110463 -0.06587542  0.06759311\n",
      " -0.06241844  0.06474056 -0.0243204   0.06695478 -0.03075263  0.00493756\n",
      "  0.06029394  0.06462792 -0.03803345 -0.04797124 -0.04959563  0.05890325\n",
      " -0.04957646  0.0389679   0.05504211 -0.05014709  0.06414802 -0.05212812\n",
      "  0.00233093  0.06318197  0.05674933  0.02712311  0.06669503  0.04302779\n",
      "  0.02490027  0.01416491  0.06852763 -0.05856865  0.02178705  0.04619698\n",
      " -0.04501358 -0.06743468  0.02019989 -0.03651068  0.01543052 -0.01940932\n",
      " -0.05995655 -0.00574789  0.05193201  0.03887472  0.01838194 -0.06397433\n",
      " -0.03331479  0.02940063 -0.01519905  0.05940966  0.00565015  0.00841178\n",
      "  0.000824    0.06830985  0.00384264  0.01893079 -0.06429159 -0.04979672\n",
      " -0.0671588  -0.01217714  0.01557181 -0.04545781  0.0475755   0.01002606\n",
      "  0.01738372 -0.06682255 -0.02919756 -0.0546734   0.0668591  -0.06357544\n",
      "  0.01055595  0.00332197  0.04452523 -0.0278058  -0.04358404 -0.0687973\n",
      "  0.049995   -0.04506052 -0.02422176 -0.05685702 -0.01180939  0.00737639\n",
      "  0.01209771  0.00398577 -0.06747646  0.03682831  0.01932335  0.01672145\n",
      " -0.06338267 -0.0492651   0.04630085  0.01720514  0.02676047 -0.04919294\n",
      "  0.05385613  0.02904331  0.05397683  0.01449795  0.06126782  0.068629\n",
      " -0.01559253  0.05296589  0.0630549   0.02432968 -0.02465812 -0.00033206\n",
      "  0.0591163  -0.04890639 -0.05489963  0.0351831  -0.02656204  0.00168441\n",
      " -0.04124434  0.04783472 -0.02011554 -0.02252284  0.0252146  -0.01258703\n",
      " -0.00773222 -0.04059961  0.04401886  0.05059525  0.02611792 -0.05892574\n",
      " -0.06170671 -0.01673575 -0.06266045 -0.0687226   0.02602493 -0.0364479\n",
      "  0.04263952  0.06330302 -0.03051377  0.02923969  0.03025208 -0.03978767\n",
      " -0.00721164 -0.0571158  -0.05520616 -0.00846966 -0.01841741  0.00674587\n",
      " -0.05722464  0.03633995 -0.01226513  0.02353884  0.05053689  0.02848265\n",
      " -0.04628806  0.06437761  0.05439693  0.04845589  0.03070693 -0.05553061\n",
      "  0.00418657  0.0348575   0.03371443  0.0600962   0.04330292  0.06767889\n",
      "  0.06714542 -0.06260844 -0.06318727 -0.05485677 -0.05567147  0.02584286\n",
      "  0.05168271  0.01566489 -0.03515926  0.02648596 -0.00496004 -0.03614463\n",
      "  0.04255292 -0.01033591 -0.06487297  0.05951215 -0.0684002  -0.06083089\n",
      "  0.0404669   0.0243694   0.0593132   0.01030068  0.0667864   0.05832795\n",
      " -0.00518828  0.04757519  0.05711955 -0.05869199 -0.05494547 -0.05529158\n",
      "  0.04152528 -0.01945598  0.04524348  0.06597628  0.02415119 -0.06079529\n",
      " -0.05005333 -0.02460117 -0.06840906 -0.02185133  0.04694499  0.02140843\n",
      "  0.05721674  0.06054112  0.0505287   0.02056168 -0.03655093  0.02148883\n",
      "  0.06754399  0.00323118  0.04342817 -0.03253661 -0.05196083 -0.03235275\n",
      "  0.05989514  0.06140703  0.04954333  0.01634078 -0.03688511 -0.01409962\n",
      "  0.06400473 -0.06727447  0.02958696  0.06715111  0.06775903 -0.04419367\n",
      "  0.02596678 -0.06642743 -0.04490585  0.03132927  0.04910694 -0.0009906\n",
      " -0.04486957  0.02537228 -0.05572845 -0.05454112  0.01676523 -0.01019822\n",
      " -0.05653217  0.03597256  0.04048498 -0.0347175   0.03325186  0.04102585\n",
      " -0.0679361   0.04656073  0.06810819 -0.02926408  0.06879888  0.03133284\n",
      "  0.04239198  0.0167882  -0.00863552  0.03852668  0.06734442 -0.06434222\n",
      "  0.01905247 -0.00140352 -0.04100924 -0.01470215 -0.03603107  0.03713542\n",
      "  0.04107311  0.05180833 -0.03572413  0.00320543  0.01493173  0.03821629\n",
      " -0.01118104  0.01618068  0.04915993  0.06620657 -0.06245042  0.04689754\n",
      " -0.06010263  0.06702644  0.06563306  0.04767862  0.0614772  -0.03216351\n",
      " -0.02132554  0.00755895 -0.00835975 -0.0426507   0.0521564   0.02789648\n",
      " -0.06324193 -0.041787   -0.05415515 -0.00774658 -0.0126619  -0.0117523\n",
      "  0.04255015  0.02002483  0.04500113  0.02817168 -0.03299684 -0.06093223\n",
      "  0.01377627  0.06468816 -0.01835671 -0.03260739 -0.06811841  0.03720801\n",
      " -0.06430075  0.05723745  0.02720393  0.04879897  0.01180991  0.05133929\n",
      "  0.00544867 -0.01695032  0.0182074  -0.01988523  0.05818709  0.01100208\n",
      " -0.04034906 -0.05976789  0.03594057  0.05079151 -0.00844088 -0.0605927\n",
      " -0.0562869   0.04544391  0.03997533 -0.05892169  0.04891544 -0.03188295\n",
      "  0.02299101  0.04422775  0.05876001 -0.04293763  0.0660886  -0.0498742\n",
      "  0.00396934  0.03287071 -0.0377703  -0.05038821  0.02214503  0.01432345\n",
      "  0.05295746  0.02610089  0.02062456 -0.00241779 -0.00370033 -0.06521156\n",
      "  0.0376488   0.06351864 -0.06583854 -0.03857715  0.04600492 -0.02816204\n",
      "  0.06704461  0.03110415]\n"
     ]
    }
   ],
   "source": [
    "# Send one example through the model to get embedding\n",
    "embeddings = embed([overview])\n",
    "print(\n",
    "    f\"Overview: {overview}\\nEmbedding Shape: {embeddings[0].shape}\\nEmbedding Value: {embeddings[0].numpy()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023b2a3-0a45-4caa-ba09-f233fd353ab5",
   "metadata": {},
   "source": [
    "#### Beam and Dataflow to serve batch predictions at scale\n",
    "While we are able to load this model in locally and serve a single prediction (which in this case is to generate an embedding), this becomes difficult as the data size grows. To serve batch predictions in a scalable manner, we can use Apache Beam and Dataflow. \n",
    "\n",
    "#### Apache Beam Pipeline\n",
    "This Apache Beam pipeline will do the following\n",
    "* Read in rows from a CSV file formatted as `movie title, overview`\n",
    "* Send the movie overviews through a pre-trained TFHub model with a custom `beam.DoFn` to generate embeddings \n",
    "* Write the movie titles and embedding representations of their overviews to a JSON file in GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadda32b-e6a4-45fc-9e05-d76bf1d5b2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing movie_embedding_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile movie_embedding_pipeline.py\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import (\n",
    "    GoogleCloudOptions, \n",
    "    PipelineOptions, \n",
    "    StandardOptions, \n",
    "    SetupOptions\n",
    ")\n",
    "\n",
    "from apache_beam.runners import DataflowRunner\n",
    "import argparse\n",
    "\n",
    "import typing \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import json \n",
    "import os \n",
    "\n",
    "# Schema of CSV file\n",
    "class Movie(typing.NamedTuple):\n",
    "    title: str\n",
    "    overview: str\n",
    "\n",
    "# DoFn to transform CSV rows to PCollection with schema\n",
    "class ParseFileDoFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        title, overview = element.split(',')\n",
    "        yield Movie(\n",
    "            title = title,\n",
    "            overview = overview\n",
    "        )\n",
    "    \n",
    "class PredictDoFn(beam.DoFn):\n",
    "    def __init__(self, hub_module):\n",
    "        self.hub_module = hub_module\n",
    "    \n",
    "    # called whenever DoFn instance is deserialized on the worker\n",
    "    def setup(self):\n",
    "        self.model = hub.load(self.hub_module)\n",
    "        \n",
    "    def process(self, element):\n",
    "        embedding = self.model([element.overview]) # tf.Tensor(shape (1, num_emb))\n",
    "        embedding = tf.squeeze(embedding) # tf.Tensor(shape (num_emb))\n",
    "        \n",
    "        yield {\n",
    "            \"id\": str(element.title),\n",
    "            \"embedding\" : embedding.numpy().tolist() #  len(list)=num_emb \n",
    "        }\n",
    "        \n",
    "def run():\n",
    "    parser = argparse.ArgumentParser(description='Movie Embedding Pipeline')\n",
    "\n",
    "    # Google Cloud options\n",
    "    parser.add_argument('--project',required=True, help='Specify Google Cloud project')\n",
    "    parser.add_argument('--region', required=True, help='Specify Google Cloud region')\n",
    "    parser.add_argument('--staging_location', required=True, help='Specify Cloud Storage bucket for staging')\n",
    "    parser.add_argument('--runner', required=True, help='Specify Apache Beam Runner')\n",
    "    parser.add_argument('--job_name', required=True, help='Job name for Dataflow Runner')\n",
    "\n",
    "    # Pipeline-specific options\n",
    "    parser.add_argument('--input_file', required=True, help='GCS path to input CSV')\n",
    "    parser.add_argument('--output_base', required=True, help='Output base for sharded JSON files')\n",
    "    parser.add_argument('--hub_module', required=True, help='URI of TF Hub model for embeddings')\n",
    "\n",
    "    opts, pipeline_opts = parser.parse_known_args()\n",
    "\n",
    "    # Setting up the Beam pipeline options.\n",
    "    options = PipelineOptions(pipeline_opts)\n",
    "    \n",
    "     # Set standard pipeline options.\n",
    "    options.view_as(StandardOptions).streaming = False\n",
    "    options.view_as(StandardOptions).runner = opts.runner\n",
    "    options.view_as(SetupOptions).save_main_session = True\n",
    "\n",
    "    # Set Google Cloud specific options.\n",
    "    google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "    google_cloud_options.project = opts.project\n",
    "    google_cloud_options.job_name = opts.job_name\n",
    "    google_cloud_options.staging_location = opts.staging_location\n",
    "    google_cloud_options.region = opts.region\n",
    "\n",
    "    # Instaniate pipeline\n",
    "    p = beam.Pipeline(DataflowRunner(), options=options)\n",
    "    \n",
    "    # Pcollection with movie titles and overviews\n",
    "    rows = (p \n",
    "        | \"Read File\" >> beam.io.ReadFromText(opts.input_file, skip_header_lines=1)\n",
    "        | \"Parse Rows\" >> beam.ParDo(ParseFileDoFn()))\n",
    "    \n",
    "    # Pcollection with movie titles and embeddings\n",
    "    index = rows | \"Generate Embeddings\" >> beam.ParDo(PredictDoFn(hub_module=opts.hub_module))\n",
    "    \n",
    "    # Write out to JSON file \n",
    "    write_json = (index \n",
    "                  | \"Format JSON\" >> beam.Map(json.dumps) \n",
    "                  | \"Write JSON\" >> beam.io.WriteToText(\n",
    "                      opts.output_base,\n",
    "                      file_name_suffix=\".json\"\n",
    "                  ))\n",
    "    p.run()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7bb786-45d8-4d11-84e6-6d8cb611f5de",
   "metadata": {},
   "source": [
    "### A deeper look at this pipeline\n",
    "\n",
    "#### Apache Beam Core Concepts\n",
    "`Pcollection`: An immutable collections of values representing data elements.\n",
    "\n",
    "`PTransform`: Represents a data processing operation, or a step, in your pipeline.\n",
    "\n",
    "`ParDo`: A transform for generic parallel processing. A `ParDo` transform considers each element in the input `PCollection`, performs some processing function on that element, and emits elements to an output `PCollection`. The processing function passed to ParDo is a `DoFn` object.\n",
    "\n",
    "`DoFn`: These are what define your pipeline's exact data processing tasks. To create a custom processing task, create a `DoFn` subclass (e.g. `class MyCustomProcessingTask(beam.DoFn)`) and write a method `def process(self, element):` where you provide the actual processing logic. You don't need to manually extract the elements from the input collection; the Beam SDKs handle that for you. Your `process` method should accept an argument `element`, which is the input element, and return an interable with its output values. You can accomplish this by emitting individual elements with `yield` statements. \n",
    "\n",
    "#### Movie Embedding with TFHub Model Pipeline\n",
    "1) `beam.io.ReadFromText`: A `PTransform` for reading text files into `str` elements. It returns one element for each line the file. With the input CSV file for our movie dataset, it will return a string element `\"{movieTitle}, {overview}\"` for each row in the CSV.\n",
    "\n",
    "2) `beam.ParDo(ParseCsv())`: A `PTransform` that applies `ParseCsv` (a custom `DoFn`), to each string element in the output `PCollection` from `beam.io.ReadFromText`. The `process` method for `ParseCsv` simply uses the `str.split()` method to split each row and return a `NamedTuple` of the movie title and overview for each example in the dataset.\n",
    "\n",
    "3) `beam.ParDo(PredictDoFn(hub_module=opts.hub_module))`. A `PTransform` that applies `PredictDoFn()` (a custom `DoFn`), to each element in the output `PCollection` from `beam.ParDo(ParseCsv())`. The `process` method for `PredictDoFn()` sends the movie overview through the universal sentence encoder that is loaded from TFHub in the `DoFn`s `setup` method. The output is a `Pcollection` where each element is a dictionary with\n",
    "    * `id`: The movie title\n",
    "    * `embedding`: The embedding of the movie overview \n",
    "\n",
    "\n",
    "4) `beam.Map(json.dumps)` A `PTransform` that maps `json.dumps` to each element in the `PCollection` output from `PredictDoFn()`. `json.dumps` converts the Python dictionary into a json string.\n",
    "\n",
    "5) `beam.io.WriteToText`: A `PTransfrm` that takes the output `PCollection` of json strings from `beam.Map(json.dumps)` and writes them to a text file. We provide `beam.io.WriteToText`\n",
    "    * `file_path_prefix`: The file path to write to\n",
    "    * `file_name_suffix`: Suffix for the files written\n",
    "    * While not provided in this pipeline, `beam.io.WriteToText` can take argument  \n",
    "    `num_shards` which specifies the number of files (shards) used for output. If not\n",
    "    set, the service will decide the optimal number of shards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fbcd4-bfbd-4a19-a633-58792ae1f806",
   "metadata": {},
   "source": [
    "Create requirement.txt file for Dataflow job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878f1b4e-89ab-4d2d-9a8f-12e0b31d1e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "tensorflow_hub==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d350ebc0-de5d-43f4-b74d-0771849d2f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: STAGING_LOCATION=gs://kylesteckler-demo/staging\n",
      "env: JOB_NAME=movie-embedding-pipeline-20220627-214540\n",
      "env: OUTPUT_BASE=gs://kylesteckler-demo/movies/data/embeddings\n",
      "env: HUB_MODULE=https://tfhub.dev/google/universal-sentence-encoder/4\n"
     ]
    }
   ],
   "source": [
    "STAGING_LOCATION = f\"gs://{BUCKET}/staging\"\n",
    "JOB_NAME = (\n",
    "    f'movie-embedding-pipeline-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    ")\n",
    "OUTPUT_BASE = f\"gs://{BUCKET}/movies/data/embeddings\"\n",
    "HUB_MODULE = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "\n",
    "\n",
    "%env STAGING_LOCATION={STAGING_LOCATION}\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "%env OUTPUT_BASE={OUTPUT_BASE}\n",
    "%env HUB_MODULE={HUB_MODULE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63ddf1-3404-425a-8e61-6c978464c4f8",
   "metadata": {},
   "source": [
    "Launch Dataflow Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3781430-bdb4-473f-aa27-bfffabbf6f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 movie_embedding_pipeline.py \\\n",
    "    --project=${PROJECT} \\\n",
    "    --region=${REGION} \\\n",
    "    --staging_location=${STAGING_LOCATION} \\\n",
    "    --runner='DataflowRunner' \\\n",
    "    --job_name=${JOB_NAME} \\\n",
    "    --input_file=${INPUT_FILE} \\\n",
    "    --output_base=${OUTPUT_BASE} \\\n",
    "    --hub_module=${HUB_MODULE} \\\n",
    "    --requirements_file='./requirements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc9be2-8357-4e0f-8433-60b83930fc8c",
   "metadata": {},
   "source": [
    "**NOTE** The pipeline will take about 10 minutes to complete. Once it's complete you can check to see the sharded files produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32726c0f-dddd-46fc-845d-032a3118c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://kylesteckler-demo/movies/data/embeddings-00000-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00001-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00002-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00003-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00004-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00005-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00006-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00007-of-00009.json\n",
      "gs://kylesteckler-demo/movies/data/embeddings-00008-of-00009.json\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {OUTPUT_BASE}*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828c70f-0893-4c40-9d1b-0a434b83e4d5",
   "metadata": {},
   "source": [
    "Look at one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5ec28-b49c-4053-89fb-dee6d2fac98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"La balsa de piedra\", \"embedding\": [-0.0005029064486734569, 0.058336496353149414, 0.004098975099623203, -0.03346201032400131, 0.0641259178519249, 0.06506840139627457, 0.05715423449873924, -0.05169349163770676, 0.05143652856349945, 0.05856018140912056, 0.05496252328157425, -0.024854077026247978, 0.019266225397586823, -0.02226070500910282, 0.013348620384931564, -0.07217089086771011, 0.016987279057502747, 0.02662324160337448, 0.045979633927345276, 0.0259920135140419, 0.047732412815093994, -0.008502245880663395, 0.06375230103731155, 0.06713975220918655, 0.0509035550057888, 0.0009528131922706962, -0.043219879269599915, 0.05272862687706947, 0.005474014673382044, -0.061405427753925323, -0.03596453368663788, -0.01561708189547062, -0.06089054048061371, -0.05055272579193115, -0.06819809973239899, -0.02577584981918335, -0.05599018558859825, 0.06125086173415184, 0.07008080184459686, -0.029677150771021843, -0.06407012790441513, 0.05200875923037529, -0.0025642698165029287, -0.06813247501850128, -0.07347270101308823, 0.06550022959709167, 0.011217220686376095, -0.015820417553186417, -0.016946306452155113, -0.008894613943994045, 0.026869501918554306, 0.00933071319013834, -0.021371375769376755, 0.010034008882939816, -0.04096146300435066, 0.00039181599277071655, -0.04813443869352341, 0.04481935128569603, 0.06064119189977646, 0.005545319523662329, -0.03730493783950806, -0.05213050916790962, -0.007757188752293587, -0.028616787865757942, -0.032912977039813995, -0.03887074440717697, 0.021209867671132088, -0.050213467329740524, 0.011712552979588509, -0.01921669766306877, -0.06226971745491028, -0.01637698896229267, 0.0115457559004426, -0.055468469858169556, -0.06907287985086441, 0.05973874777555466, -0.06986847519874573, 0.06485890597105026, 0.06615514308214188, 0.06047181040048599, 0.06792382150888443, 0.05461796373128891, 0.045119091868400574, 0.00037270894972607493, 0.004755042959004641, -0.006320766173303127, -0.045430608093738556, 0.049962468445301056, -0.0660095363855362, 0.022688118740916252, -0.0539257675409317, 0.03594938665628433, 0.04080021753907204, -0.06791236251592636, -0.040895842015743256, -0.0031366462353616953, 0.05767391622066498, 0.011175627820193768, 0.07413364201784134, 0.03763483837246895, -0.033542513847351074, -0.05260848626494408, 0.044060226529836655, 0.029027311131358147, 7.287767948582768e-05, -0.055730804800987244, -0.06027783453464508, -0.05106832832098007, 0.04322364553809166, -0.03492627665400505, 0.04419891536235809, -0.009668562561273575, 0.04928990453481674, -0.033008284866809845, 0.05487103387713432, -0.021677589043974876, -0.0006507057696580887, -0.053200673311948776, 0.007887776009738445, 0.06253068894147873, 0.05030909180641174, 0.06003345921635628, -0.06787720322608948, 0.013029496185481548, 0.06254375725984573, -0.03542151302099228, 0.074313223361969, -0.04554654285311699, 0.01719885692000389, 0.045113202184438705, 0.04124832525849342, 0.06367506831884384, 0.06529684364795685, 0.009220619685947895, 0.0477769635617733, 0.02745339833199978, -0.0075635528191924095, 0.03005973808467388, -0.058235861361026764, -0.02295910008251667, -0.0333060584962368, 0.07431738078594208, -0.04328079894185066, 0.05216105654835701, 0.0646493136882782, 0.004839826840907335, 0.000770241895224899, 0.0034752695355564356, 0.028771046549081802, -0.05973425880074501, 0.012380826286971569, -0.06405318528413773, 0.02523943781852722, -0.0036009326577186584, 0.011993061751127243, 0.006273466628044844, 0.0075994678772985935, 0.03782399371266365, -0.016352776437997818, 0.037403300404548645, -0.04156428575515747, -7.018943142611533e-05, -0.04351438209414482, 0.031997524201869965, 0.01059940829873085, 0.03522554412484169, 0.07400013506412506, -0.05132022500038147, 0.002347117057070136, -0.06307375431060791, -0.05336791276931763, -0.0601995512843132, 0.05288532003760338, -0.06018174812197685, -0.031545381993055344, -0.06170489266514778, 0.06248059868812561, -0.001986138755455613, 0.004405008163303137, 0.04340481758117676, 0.06263371556997299, 0.055759236216545105, 0.05437975749373436, -0.013083958998322487, -0.07191452383995056, 0.01278666127473116, 0.01726544462144375, -0.04628526419401169, 0.040493011474609375, -0.06308713555335999, 0.06428521871566772, -0.06690617650747299, -0.07204152643680573, 0.012248950079083443, 0.03164453059434891, -0.0649104043841362, -0.03634829819202423, 0.054916270077228546, -0.04454578831791878, 0.02055727317929268, -0.07418757677078247, 0.011244104243814945, 0.015379289165139198, -0.019494090229272842, 0.007812926545739174, -0.004743027500808239, 0.04955312982201576, -0.02888612262904644, -0.005370078608393669, -0.06751571595668793, 0.03053983300924301, -0.02392699010670185, 0.00822379533201456, -0.03126564621925354, -0.06698909401893616, 0.0468018501996994, -0.00949464924633503, -0.02021029032766819, -0.05734434351325035, -0.01884857751429081, 0.022304747253656387, 0.07162649929523468, -0.04132189601659775, -0.0650511160492897, -0.056671321392059326, 0.016506368294358253, 0.0384993776679039, -0.04843422397971153, 0.052575770765542984, 0.020784132182598114, -0.026224534958600998, 0.05781911313533783, -0.028475428000092506, -0.07433412224054337, -0.04848083481192589, -0.00905042327940464, -0.05149957910180092, 0.026516107842326164, 0.04841575399041176, -0.0020412220619618893, -0.017731592059135437, 0.05410493165254593, -0.039255499839782715, -0.06421464681625366, 0.056859079748392105, 0.05953824520111084, -0.022357219830155373, -0.016066519543528557, 0.05246945843100548, 0.05280335620045662, 0.05424344167113304, 0.0461127869784832, -0.06691990792751312, -0.0015722280368208885, 0.004279586486518383, -0.0002542099973652512, -0.015371523797512054, 0.07408850640058517, 0.011500230990350246, 0.01837587170302868, 0.04990347474813461, 0.027185624465346336, -0.055070240050554276, -0.00848697405308485, -0.045672155916690826, 0.05440613627433777, -0.035153791308403015, -0.03116539679467678, -0.007643243297934532, -0.04318881779909134, 0.016016487032175064, 0.05030831694602966, 0.002038004109635949, 0.06856030225753784, -0.024886805564165115, -0.056041065603494644, -0.05495022237300873, 0.02790941298007965, -0.01725686714053154, -0.04145433381199837, -0.02235567755997181, -0.053737472742795944, -0.05849341303110123, -0.02798326499760151, -0.04501541331410408, -0.03296729177236557, -0.06542231142520905, 0.04297201335430145, -0.060299523174762726, 0.05970379710197449, -0.03495004400610924, 0.001382339745759964, 0.05741652101278305, 0.034242983907461166, -0.02911543659865856, -0.020478926599025726, 0.034569479525089264, 0.03101731650531292, -0.06816215813159943, 0.04604415223002434, -0.06342809647321701, 0.04214733839035034, 0.045003727078437805, -0.008730676025152206, 0.034174494445323944, 0.015699483454227448, -0.0523524284362793, -0.020802393555641174, -0.021539364010095596, -0.06144948676228523, -0.04901203140616417, 0.001333726802840829, 0.07202161848545074, -0.032060232013463974, -0.01151569839566946, -0.05732092261314392, 0.06490358710289001, 0.06876634806394577, 0.07252896577119827, 0.06675592064857483, -0.016776369884610176, 0.027004892006516457, -0.017779991030693054, -0.06490995734930038, -0.055793896317481995, -0.0068700797855854034, -0.017311938107013702, 0.048326101154088974, 0.03755272552371025, 0.07083547115325928, 0.0023205801844596863, 0.03213336691260338, -0.043276526033878326, 0.07208186388015747, -0.0544419139623642, 0.02171812392771244, -0.034490711987018585, 0.04789162054657936, -0.018113769590854645, -0.013211245648562908, -0.00959801860153675, 0.06697487086057663, -0.017691459506750107, -0.021666010841727257, 0.012765422463417053, -0.06467163562774658, -0.018756380304694176, -0.00958902295678854, -0.008057571947574615, 0.02748856134712696, -0.04740281030535698, 0.022895053029060364, 0.03686767816543579, 0.0035433336161077023, 0.0585593543946743, 0.012295176275074482, -0.07344217598438263, -0.05424431338906288, 0.023414602503180504, -0.018740855157375336, -0.020595507696270943, -0.021302735432982445, 0.03590347617864609, -0.024831702932715416, 0.02547249011695385, -0.05451297014951706, 0.07324755191802979, -0.06342796236276627, 0.04381399601697922, 0.044435299932956696, -0.06977520883083344, 0.012979093007743359, -0.04086153954267502, -0.028826890513300896, -0.0012894232058897614, 0.0435023307800293, 0.07080578804016113, -0.05145329609513283, -0.0031076075974851847, 0.06944923847913742, 0.07167831808328629, 0.024848030880093575, 0.06509272009134293, -0.04398062825202942, 0.0447457917034626, -0.06804042309522629, -0.06910919398069382, 0.06102261319756508, -0.051240019500255585, 0.06278069317340851, -0.054696403443813324, 0.05398363992571831, -0.006026354618370533, 0.047780610620975494, 0.008619813248515129, -0.025493254885077477, -0.03655107691884041, -0.03717688098549843, -0.06611870974302292, 0.021240372210741043, -0.03424513712525368, -0.06549674272537231, -0.01156568806618452, -0.02142278291285038, 0.022925198078155518, 0.026665693148970604, -0.04414704442024231, 0.04026339203119278, 0.03190426155924797, -0.0011634528636932373, -0.060832325369119644, -0.03369126841425896, -0.0023538190871477127, -0.06834454089403152, 0.04058774560689926, -0.017503386363387108, -0.06178586930036545, 0.03283190354704857, -0.01750367134809494, 0.06110292300581932, 0.059251002967357635, -0.04192131757736206, -0.038213662803173065, 0.032053690403699875, -0.052515409886837006, -0.06048457697033882, -0.042997416108846664, 0.053332362323999405, 0.034084394574165344, 0.021913478150963783, 0.028316162526607513, -0.05395035073161125, -0.05350637435913086, 0.05786186829209328, 0.05181056633591652, -3.4286913432879373e-05, 0.03622213378548622, 0.049014266580343246, 0.05330747365951538, 0.059170424938201904, -0.044111669063568115, -0.002229497069492936, -0.03737209364771843, 0.05052477493882179, -0.03763991594314575, -0.05858278647065163, -0.014332495629787445, 0.059242572635412216, 0.004671955481171608, 0.01231235358864069, -0.05985018238425255, -0.03664815425872803, 0.05621424317359924, 0.01998346671462059, 0.019821926951408386, 0.007626904174685478, -0.01759306527674198, 0.059799838811159134, -0.0722116008400917, -0.04027412459254265, -0.03227859362959862, 0.005884100683033466, -0.021091222763061523, 0.030118266120553017, -0.07373566180467606, 0.059886086732149124, 0.04315883293747902, 0.040658507496118546, 0.044576168060302734, -0.027449365705251694, -0.0631176233291626, 0.03883046656847, 0.003974453546106815, 0.048796240240335464, -0.042728450149297714, 0.048512622714042664, 0.03116505779325962, 0.01851680874824524, -0.05090806260704994, -0.06643246859312057, 0.03521452471613884, 0.06513787060976028, 0.0170835442841053, -0.06650999933481216, -0.006434474606066942, 0.014765532687306404, 0.04102383181452751, 0.023969396948814392, 0.05365627631545067, -0.051317133009433746, -0.034942906349897385, -0.029653292149305344, 0.06404899805784225, 0.05036860704421997, 0.013294430449604988, -0.05273929238319397, 0.05329342931509018, -0.01438757125288248, -0.03578329086303711, -0.03418424725532532, -0.06725219637155533, -0.03942754492163658, -0.02238558605313301, -0.07399154454469681, 0.05064482241868973, -0.059490252286195755, 0.025461360812187195, 0.07393486052751541, 0.008125998079776764, -0.035574812442064285, -0.06506287306547165, -0.0718737542629242]}\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat PASTE_ONE_FILE_PATH_HERE | head -1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
