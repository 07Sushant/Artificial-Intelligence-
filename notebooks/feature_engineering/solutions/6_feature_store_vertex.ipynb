{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "# Vertex AI Feature Store\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "In this notebook, you will learn\n",
    " 1. how to import your features into Feature Store.\n",
    " 2. how to serve online prediction requests using the imported features.\n",
    " 3. how to access imported features in offline jobs, such as training jobs.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, we introduce the Vertex AI Feature Store, a managed cloud service for machine learning engineers and data scientists to store, serve, manage and share machine learning features at a large scale.\n",
    "\n",
    "We'll use a movie recommendation dataset as an example. The task is to train a model to predict if a user is going to watch a movie and serve this model online. Under the hood, we'll be using components of Cloud Storage and Bigtable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install  packages\n",
    "After running the cell below, restart your kernel so it can find the packages. You can restart kernel from Kernel -> Restart Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wyy5Lbnzg5fi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/googleapis/python-aiplatform.git@main-test\n",
      "  Cloning https://github.com/googleapis/python-aiplatform.git (to revision main-test) to /tmp/pip-req-build-ntqouw8u\n",
      "  Running command git clone -q https://github.com/googleapis/python-aiplatform.git /tmp/pip-req-build-ntqouw8u\n",
      "  Running command git checkout -b main-test --track origin/main-test\n",
      "  Switched to a new branch 'main-test'\n",
      "  Branch 'main-test' set up to track remote branch 'main-test' from 'origin'.\n",
      "  Resolved https://github.com/googleapis/python-aiplatform.git to commit 59808e63aa07a725de03721ecdd4efef9e1b33e2\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.22.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==0.7.1) (1.31.2)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==0.7.1) (1.19.0)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==0.7.1) (1.42.2)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==0.7.1) (2.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (58.0.4)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (21.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (2021.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (3.18.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (1.38.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (0.2.7)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==0.7.1) (2.0.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==0.7.1) (2.0.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==0.7.1) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==0.7.1) (2021.5.30)\n",
      "Building wheels for collected packages: google-cloud-aiplatform\n",
      "  Building wheel for google-cloud-aiplatform (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-cloud-aiplatform: filename=google_cloud_aiplatform-0.7.1-py2.py3-none-any.whl size=1696810 sha256=44fbd9eea35e399304c8836e4f617d3ea328a6f09fcb54e2e41fb049dbcc520b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-b844xp2m/wheels/17/ff/e0/00d0fec24bcb16097ce47b6894c6844b347b9fc2b413623116\n",
      "Successfully built google-cloud-aiplatform\n",
      "Installing collected packages: google-cloud-aiplatform\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.5.0\n",
      "    Uninstalling google-cloud-aiplatform-1.5.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-pipeline-components 0.1.1 requires google-cloud-aiplatform>=1.0.0, but you have google-cloud-aiplatform 0.7.1 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-aiplatform-0.7.1\n"
     ]
    }
   ],
   "source": [
    "! pip install --user --upgrade git+https://github.com/googleapis/python-aiplatform.git@main-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Select a GPU runtime\n",
    "\n",
    "**Make sure you're running this notebook in a GPU runtime if you have that option. In Colab, select \"Runtime --> Change runtime type > GPU\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "#### Set your project ID\n",
    "Use the command below to get your Project ID and set it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current GCP Project Name is qwiklabs-gcp-04-4b26761f85f9\n"
     ]
    }
   ],
   "source": [
    "!echo \"Your current GCP Project Name is\" $(gcloud config list project --format \"value(core.project)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-4b26761f85f9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr--iN2kAylZ"
   },
   "source": [
    "Note, if you are running this lab in a Google Cloud Notebook, then your environment is already\n",
    "authenticated. However, if you are running the code in this lab in a Colab or another environment you will need to \n",
    "authenticate you account via OAuth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAL9Y4VTOLT1"
   },
   "source": [
    "## Step 1. Create dataset for output\n",
    "\n",
    "You need a BigQuery dataset to host the output data in `us-central1`. Input the name of the dataset you want to created and specify the name of the table you want to store the output later. These will be used later in the notebook. Make sure that the table name does NOT already exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4Oc-jrd6Ow7N"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QOaGi2PrEAwA"
   },
   "outputs": [],
   "source": [
    "# Output dataset\n",
    "DESTINATION_DATA_SET = \"movie_predictions\"  # @param {type:\"string\"}\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "DESTINATION_DATA_SET = \"{prefix}_{timestamp}\".format(\n",
    "    prefix=DESTINATION_DATA_SET, timestamp=TIMESTAMP\n",
    ")\n",
    "\n",
    "# Output table. Make sure that the table does NOT already exist;\n",
    "# the BatchReadFeatureValues API cannot overwrite an existing table\n",
    "DESTINATION_TABLE_NAME = \"training_data\"  # @param {type:\"string\"}\n",
    "\n",
    "DESTINATION_PATTERN = \"bq://{project}.{dataset}.{table}\"\n",
    "DESTINATION_TABLE_URI = DESTINATION_PATTERN.format(\n",
    "    project=PROJECT_ID, dataset=DESTINATION_DATA_SET, table=DESTINATION_TABLE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the dataset in your project. After running this cell, you can navigate to [BigQuery](https://console.cloud.google.com/bigquery) in the GCP console to verify it was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RKhmymT-O0vy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset qwiklabs-gcp-04-4b26761f85f9.movie_predictions_20211007204042\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "dataset_id = \"{}.{}\".format(client.project, DESTINATION_DATA_SET)\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = REGION\n",
    "dataset = client.create_dataset(dataset)\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll import some necessary libraries. Here is a link to the [client library documentation](https://googleapis.dev/python/aiplatform/latest/index.html) and [the library repo](https://github.com/googleapis/python-aiplatform) on github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform_v1beta1 import (\n",
    "    FeaturestoreOnlineServingServiceClient, FeaturestoreServiceClient)\n",
    "from google.cloud.aiplatform_v1beta1.types import FeatureSelector, IdMatcher\n",
    "from google.cloud.aiplatform_v1beta1.types import \\\n",
    "    entity_type as entity_type_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import feature as feature_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import \\\n",
    "    featurestore as featurestore_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import \\\n",
    "    featurestore_monitoring as featurestore_monitoring_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import \\\n",
    "    featurestore_online_service as featurestore_online_service_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import \\\n",
    "    featurestore_service as featurestore_service_pb2\n",
    "from google.cloud.aiplatform_v1beta1.types import io as io_pb2\n",
    "from google.protobuf.duration_pb2 import Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define some constants we'll use later. Namely, we need to set the API endpoint and specify the csv file that we'll use to load features into our feature store.\n",
    "\n",
    "We'll also create the clients for CRUD (Create, Read, Update and Delete) and for reading features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other than project ID and featurestore ID and endpoints needs to be set\n",
    "API_ENDPOINT = \"us-central1-aiplatform.googleapis.com\"  # @param {type:\"string\"}\n",
    "INPUT_CSV_FILE = \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movie_prediction.csv\"\n",
    "\n",
    "# Create admin_client for CRUD and data_client for reading feature values.\n",
    "admin_client = FeaturestoreServiceClient(client_options={\"api_endpoint\": API_ENDPOINT})\n",
    "data_client = FeaturestoreOnlineServingServiceClient(\n",
    "    client_options={\"api_endpoint\": API_ENDPOINT}\n",
    ")\n",
    "\n",
    "# Represents featurestore resource path.\n",
    "BASE_RESOURCE_PATH = admin_client.common_location_path(PROJECT_ID, REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buQBIv3ZL3A0"
   },
   "source": [
    "## Step 2. Create Featurestore and Define Schema\n",
    "\n",
    "### Some Terminology and Concepts\n",
    "\n",
    "Feature Store organizes data with the following 3 important hierarchical concepts:\n",
    "```\n",
    "Featurestore -> EntityType -> Feature\n",
    "```\n",
    "* **Featurestore**: the place to store your features\n",
    "* **EntityType**: under a Featurestore, an *EntityType* describes an object to be modeled, real one or virtual one.\n",
    "* **Feature**: under an EntityType, a *feature* describes an attribute of the EntityType\n",
    "\n",
    "In the movie prediction example, you will create a featurestore called *movie_prediction*. This store has 2 entity types: *Users* and *Movies*. The Users entity type has the age, gender, and like genres features. The Movies entity type has the genres and average rating features.\n",
    "\n",
    "\n",
    "### Create Featurestore\n",
    "\n",
    "The method to create a featurestore returns a\n",
    "[long-running operation](https://google.aip.dev/151) (LRO). An LRO starts an asynchronous job. LROs are returned for other API\n",
    "methods too, such as updating or deleting a featurestore. Calling\n",
    "`create_fs_lro.result()` waits for the LRO to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FscHZa0DXjmC"
   },
   "outputs": [],
   "source": [
    "FEATURESTORE_ID = \"movie_prediction\"\n",
    "\n",
    "create_lro = admin_client.create_featurestore(\n",
    "    featurestore_service_pb2.CreateFeaturestoreRequest(\n",
    "        parent=BASE_RESOURCE_PATH,\n",
    "        featurestore_id=FEATURESTORE_ID,\n",
    "        featurestore=featurestore_pb2.Featurestore(\n",
    "            online_serving_config=featurestore_pb2.Featurestore.OnlineServingConfig(\n",
    "                fixed_node_count=1\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "57V8eVcB5VFZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wait for LRO to finish and get the LRO result.\n",
    "print(create_lro.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take some time to finish (a couple minutes). Once it's completed, you can navigate to [Vertex AI Features](https://console.cloud.google.com/vertex-ai/features) to see your new Feature Store. At this stage there are no feautures yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag8pCQ7rNjVf"
   },
   "source": [
    "More programatically, you can use [GetFeaturestore](https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.GetFeaturestore) or [ListFeaturestores](https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeaturestores) to check if the Featurestore was successfully created. The following example gets the details of the Featurestore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eKhD4q8rXjmM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction\"\n",
       "create_time {\n",
       "  seconds: 1633362939\n",
       "  nanos: 80712000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1633362939\n",
       "  nanos: 145883000\n",
       "}\n",
       "etag: \"AMEw9yPXkiRZzETiz15Xx6EfVQxhA6FRTacEOic_1f9mz0LhcQquVqnko4nQgRyjpBk=\"\n",
       "online_serving_config {\n",
       "  fixed_node_count: 1\n",
       "}\n",
       "state: STABLE"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_client.get_featurestore(\n",
    "    name=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpmJq75zXjmT"
   },
   "source": [
    "### Create Entity Type\n",
    "You can specify a monitoring config which will by default be inherited by all Features under this EntityType.\n",
    "\n",
    "We'll create two Entity Types below. One for `users` which will have monitoring enabled and one for `movies` which will not have monitoring enabled. For Features with monitoring enabled, distribution statistics are updated periodically in the console.\n",
    "\n",
    "You can enable or disable feature monitoring at the feature level as well, which overrides the monitoring configuration in the feature's entity type. For example, if monitoring is enabled for the entity type, you can change the monitoring configuration or disable it for particular features. When monitoring is enabled you can view the properties and metrics for a feature in the console: sample [properties](https://storage.googleapis.com/cloud-samples-data/ai-platform-unified/datasets/featurestore/Feature%20Properties.png), sample [metrics](https://storage.googleapis.com/cloud-samples-data/ai-platform-unified/datasets/featurestore/Feature%20Snapshot%20Distribution.png). \n",
    "\n",
    "For more information about the monitoring metrics, see [FeatureStatsAnomaly](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.featurestores.entityTypes.features#FeatureStatsAnomaly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s9eZ7aJLXjmT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users\"\n",
      "etag: \"AMEw9yOhLcfSPydABQGpcW21kU5PBG42a7ngejYRWYC3FWY4eqJj\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create users entity type with monitoring enabled.\n",
    "# All Features belonging to this EntityType will by default inherit the monitoring config.\n",
    "users_entity_type_lro = admin_client.create_entity_type(\n",
    "    featurestore_service_pb2.CreateEntityTypeRequest(\n",
    "        parent=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
    "        entity_type_id=\"users\",\n",
    "        entity_type=entity_type_pb2.EntityType(\n",
    "            description=\"Users entity\",\n",
    "            monitoring_config=featurestore_monitoring_pb2.FeaturestoreMonitoringConfig(\n",
    "                snapshot_analysis=featurestore_monitoring_pb2.FeaturestoreMonitoringConfig.SnapshotAnalysis(\n",
    "                    monitoring_interval=Duration(seconds=86400),  # 1 day\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Similarly, wait for EntityType creation operation.\n",
    "print(users_entity_type_lro.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hJqNOttvOc2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies\"\n",
      "etag: \"AMEw9yMIvKXtJdSiwaSfQCTcvwH0UBUF06S0olDSiAnHFcpHvwV2\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create movies entity type without a monitoring configuration.\n",
    "movies_entity_type_lro = admin_client.create_entity_type(\n",
    "    featurestore_service_pb2.CreateEntityTypeRequest(\n",
    "        parent=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
    "        entity_type_id=\"movies\",\n",
    "        entity_type=entity_type_pb2.EntityType(description=\"Movies entity\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Similarly, wait for EntityType creation operation.\n",
    "print(movies_entity_type_lro.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJW4q-0jO2Xf"
   },
   "source": [
    "### Create Features\n",
    "\n",
    "Next, we'll create features for our `movie_prediction` Feature Store.\n",
    "\n",
    "For the `users` entity, we'll create features for `age`, `gender` and `liked_genres`. \n",
    "\n",
    "Note that `age` Feature leaves the monitoring config unset, which means it'll inherit the config from EntityType, while `gender` Feature explicitly disables monitoring and `liked_genres` Feature is a STRING_ARRAY type, so it is automatically excluded from monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZJD7-6GFqc1z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/age\"\n",
       "  etag: \"AMEw9yPcILCzGR2-JciSVe7CjexqnOEC20XkktPVrCm8pZLkOBj7\"\n",
       "}\n",
       "features {\n",
       "  name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/gender\"\n",
       "  etag: \"AMEw9yP5NjCmk6nH8Fxs1kcCSMQhov7cokbET7yHbRvbDtDg004z\"\n",
       "}\n",
       "features {\n",
       "  name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/liked_genres\"\n",
       "  etag: \"AMEw9yNn3Z7qGLG74ieWJLfX0XmYz75VyLrno2stVCHGmVblD4pL\"\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features for the 'users' entity.\n",
    "# 'age' Feature leaves the monitoring config unset, which means it'll inherit the config from EntityType.\n",
    "# 'gender' Feature explicitly disables monitoring.\n",
    "# 'liked_genres' Feature is a STRING_ARRAY type, so it is automatically excluded from monitoring.\n",
    "\n",
    "admin_client.batch_create_features(\n",
    "    parent=admin_client.entity_type_path(PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"),\n",
    "    requests=[\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.INT64,\n",
    "                description=\"User age\",\n",
    "            ),\n",
    "            feature_id=\"age\",\n",
    "        ),\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
    "                description=\"User gender\",\n",
    "                monitoring_config=featurestore_monitoring_pb2.FeaturestoreMonitoringConfig(\n",
    "                    snapshot_analysis=featurestore_monitoring_pb2.FeaturestoreMonitoringConfig.SnapshotAnalysis(\n",
    "                        disabled=True,\n",
    "                    ),\n",
    "                ),\n",
    "            ),\n",
    "            feature_id=\"gender\",\n",
    "        ),\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.STRING_ARRAY,\n",
    "                description=\"An array of genres that this user liked\",\n",
    "            ),\n",
    "            feature_id=\"liked_genres\",\n",
    "        ),\n",
    "    ],\n",
    ").result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create features for the movie types within the `movies` EntityType. We'll make features for `title`, `genres` and `average_rating`.\n",
    "\n",
    "Note, the `title` feature enables monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tWx_wI_FS8tE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/title\"\n",
       "  etag: \"AMEw9yPrqdCMwwcMFstDR_w2UlMfEZ2agIUcGL_FYrkYbHUzPsN-\"\n",
       "}\n",
       "features {\n",
       "  name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/genres\"\n",
       "  etag: \"AMEw9yNzNfZ55gwS-OxXt9umwird9lB9903EADaHvp-MDMiKSXX3\"\n",
       "}\n",
       "features {\n",
       "  name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/average_rating\"\n",
       "  etag: \"AMEw9yPvltWGPvIAQiVUxMUik8vi4-sYBhyGDJ14S5bfzMOzAJ-K\"\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create features for movies type.\n",
    "# 'title' Feature enables monitoring.\n",
    "admin_client.batch_create_features(\n",
    "    parent=admin_client.entity_type_path(PROJECT_ID, REGION, FEATURESTORE_ID, \"movies\"),\n",
    "    requests=[\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
    "                description=\"The title of the movie\",\n",
    "                monitoring_config=featurestore_monitoring_pb2.FeaturestoreMonitoringConfig(\n",
    "                    snapshot_analysis=featurestore_monitoring_pb2.FeaturestoreMonitoringConfig.SnapshotAnalysis(\n",
    "                        monitoring_interval=Duration(seconds=172800),  # 2 days\n",
    "                    ),\n",
    "                ),\n",
    "            ),\n",
    "            feature_id=\"title\",\n",
    "        ),\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.STRING,\n",
    "                description=\"The genres of the movie\",\n",
    "            ),\n",
    "            feature_id=\"genres\",\n",
    "        ),\n",
    "        featurestore_service_pb2.CreateFeatureRequest(\n",
    "            feature=feature_pb2.Feature(\n",
    "                value_type=feature_pb2.Feature.ValueType.DOUBLE,\n",
    "                description=\"The average rating for the movie, range is [1.0-5.0]\",\n",
    "            ),\n",
    "            feature_id=\"average_rating\",\n",
    "        ),\n",
    "    ],\n",
    ").result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUVOzrAb1AFX"
   },
   "source": [
    "## Search created features\n",
    "\n",
    "While the [ListFeatures](https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.ListFeatures) method allows you to easily view all features of a single\n",
    "entity type, the [SearchFeatures](https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1beta1#google.cloud.aiplatform.v1beta1.FeaturestoreService.SearchFeatures) method searches across all featurestores\n",
    "and entity types in a given location (such as `us-central1`). This can help you discover features that were created by someone else.\n",
    "\n",
    "You can query based on feature properties including `feature ID`, `entity type ID`,\n",
    "and `feature description`. You can also limit results by filtering on a specific\n",
    "`featurestore`, feature value type, and/or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Hs_7T_hs17ew"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/average_rating\"\n",
       " description: \"The average rating for the movie, range is [1.0-5.0]\"\n",
       " create_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 638347000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 638347000\n",
       " },\n",
       " name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/genres\"\n",
       " description: \"The genres of the movie\"\n",
       " create_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 636248000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 636248000\n",
       " },\n",
       " name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/title\"\n",
       " description: \"The title of the movie\"\n",
       " create_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 634241000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 634241000\n",
       " },\n",
       " name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/age\"\n",
       " description: \"User age\"\n",
       " create_time {\n",
       "   seconds: 1633639956\n",
       "   nanos: 32444000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639956\n",
       "   nanos: 32444000\n",
       " },\n",
       " name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/gender\"\n",
       " description: \"User gender\"\n",
       " create_time {\n",
       "   seconds: 1633639956\n",
       "   nanos: 33916000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639956\n",
       "   nanos: 33916000\n",
       " },\n",
       " name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users/features/liked_genres\"\n",
       " description: \"An array of genres that this user liked\"\n",
       " create_time {\n",
       "   seconds: 1633639956\n",
       "   nanos: 35813000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639956\n",
       "   nanos: 35813000\n",
       " }]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for all features across all featurestores.\n",
    "list(admin_client.search_features(location=BASE_RESOURCE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcxsiBUiIyvE"
   },
   "source": [
    "Now, narrow down the search to features that are of type `DOUBLE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a9ovJSyEI4OZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/average_rating\"\n",
       " description: \"The average rating for the movie, range is [1.0-5.0]\"\n",
       " create_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 638347000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 638347000\n",
       " }]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for all features with value type `DOUBLE`\n",
    "list(\n",
    "    admin_client.search_features(\n",
    "        featurestore_service_pb2.SearchFeaturesRequest(\n",
    "            location=BASE_RESOURCE_PATH, query=\"value_type=DOUBLE\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtr9tvH6JAOY"
   },
   "source": [
    "Or, limit the search results to features with specific keywords in their ID and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3G1mNV1uJFBC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/movies/features/title\"\n",
       " description: \"The title of the movie\"\n",
       " create_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 634241000\n",
       " }\n",
       " update_time {\n",
       "   seconds: 1633639961\n",
       "   nanos: 634241000\n",
       " }]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter on feature value type and keywords.\n",
    "list(\n",
    "    admin_client.search_features(\n",
    "        featurestore_service_pb2.SearchFeaturesRequest(\n",
    "            location=BASE_RESOURCE_PATH, query=\"feature_id:title AND value_type=STRING\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3n5XdK8Xjmw"
   },
   "source": [
    "## Step 3. Import Feature Values\n",
    "\n",
    "You need to import feature values before you can use them for online/offline serving. Here, we'll see how to import feature values by calling the `ImportFeatureValues` API using the Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlqJ-QdTcs6W"
   },
   "source": [
    "### Source Data Format and Layout\n",
    "\n",
    "As mentioned above, BigQuery table/Avro/CSV are supported. No matter what format you are using, each imported entity *must* have an ID; also, each entity can *optionally* have a timestamp, sepecifying when the feature values are generated. This Colab uses Avro as an input, located at this public [bucket](https://pantheon.corp.google.com/storage/browser/cloud-samples-data/ai-platform-unified/datasets/featurestore;tab=objects?project=storage-samples&prefix=&forceOnObjectsSortingFiltering=false). The Avro schemas are as follows:\n",
    "\n",
    "**For the Users entity**:\n",
    "```\n",
    "schema = {\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"User\",\n",
    "  \"fields\": [\n",
    "      {\n",
    "       \"name\":\"user_id\",\n",
    "       \"type\":[\"null\",\"string\"]\n",
    "      },\n",
    "      {\n",
    "       \"name\":\"age\",\n",
    "       \"type\":[\"null\",\"long\"]\n",
    "      },\n",
    "      {\n",
    "       \"name\":\"gender\",\n",
    "       \"type\":[\"null\",\"string\"]\n",
    "      },\n",
    "      {\n",
    "       \"name\":\"liked_genres\",\n",
    "       \"type\":{\"type\":\"array\",\"items\":\"string\"}\n",
    "      },\n",
    "      {\n",
    "       \"name\":\"update_time\",\n",
    "       \"type\":[\"null\",{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"}]\n",
    "      },\n",
    "  ]\n",
    " }\n",
    "```\n",
    "\n",
    "**For the Movies entity**\n",
    "```\n",
    "schema = {\n",
    " \"type\": \"record\",\n",
    " \"name\": \"Movie\",\n",
    " \"fields\": [\n",
    "     {\n",
    "      \"name\":\"movie_id\",\n",
    "      \"type\":[\"null\",\"string\"]\n",
    "     },\n",
    "     {\n",
    "      \"name\":\"average_rating\",\n",
    "      \"type\":[\"null\",\"double\"]\n",
    "     },\n",
    "     {\n",
    "      \"name\":\"title\",\n",
    "      \"type\":[\"null\",\"string\"]\n",
    "     },\n",
    "     {\n",
    "      \"name\":\"genres\",\n",
    "      \"type\":[\"null\",\"string\"]\n",
    "     },\n",
    "     {\n",
    "      \"name\":\"update_time\",\n",
    "      \"type\":[\"null\",{\"type\":\"long\",\"logicalType\":\"timestamp-micros\"}]\n",
    "     },\n",
    " ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7DyDa6chbJx"
   },
   "source": [
    "### Import feature values for Users\n",
    "\n",
    "When importing features, you specify the following in your request:\n",
    "\n",
    "*   Data source format: BigQuery Table/Avro/CSV\n",
    "*   Data source URL\n",
    "*   Destination: featurestore/entity types/features to be imported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RUhm6-yzXjmx"
   },
   "outputs": [],
   "source": [
    "import_users_request = featurestore_service_pb2.ImportFeatureValuesRequest(\n",
    "    entity_type=admin_client.entity_type_path(\n",
    "        PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
    "    ),\n",
    "    avro_source=io_pb2.AvroSource(\n",
    "        # Source\n",
    "        gcs_source=io_pb2.GcsSource(\n",
    "            uris=[\n",
    "                \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/users.avro\"\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    entity_id_field=\"user_id\",\n",
    "    feature_specs=[\n",
    "        # Features\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"age\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"gender\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"liked_genres\"),\n",
    "    ],\n",
    "    feature_time_field=\"update_time\",\n",
    "    worker_count=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qwznuUiwjwJF"
   },
   "outputs": [],
   "source": [
    "# Start to import, will take a couple of minutes\n",
    "ingestion_lro = admin_client.import_feature_values(import_users_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sDl3ZcrF64T"
   },
   "outputs": [],
   "source": [
    "# Polls for the LRO status and prints when the LRO has completed\n",
    "ingestion_lro.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laXdJPIqkLJO"
   },
   "source": [
    "### Import feature values for Movies\n",
    "\n",
    "Similarly, import feature values for 'movies' into the featurestore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-W1lCxgDl6iR"
   },
   "outputs": [],
   "source": [
    "import_movie_request = featurestore_service_pb2.ImportFeatureValuesRequest(\n",
    "    entity_type=admin_client.entity_type_path(\n",
    "        PROJECT_ID, REGION, FEATURESTORE_ID, \"movies\"\n",
    "    ),\n",
    "    avro_source=io_pb2.AvroSource(\n",
    "        gcs_source=io_pb2.GcsSource(\n",
    "            uris=[\n",
    "                \"gs://cloud-samples-data-us-central1/vertex-ai/feature-store/datasets/movies.avro\"\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    entity_id_field=\"movie_id\",\n",
    "    feature_specs=[\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"title\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(id=\"genres\"),\n",
    "        featurestore_service_pb2.ImportFeatureValuesRequest.FeatureSpec(\n",
    "            id=\"average_rating\"\n",
    "        ),\n",
    "    ],\n",
    "    feature_time_field=\"update_time\",\n",
    "    worker_count=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-MATtpvm3HI"
   },
   "outputs": [],
   "source": [
    "# Start to import, will take a couple of minutes\n",
    "ingestion_lro = admin_client.import_feature_values(import_movie_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpaK3yRCnNnI"
   },
   "outputs": [],
   "source": [
    "# Polls for the LRO status and prints when the LRO has completed\n",
    "ingestion_lro.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TdxPYdDXjnA"
   },
   "source": [
    "## Online serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezJIMyU-XjnB"
   },
   "source": [
    "The\n",
    "[Online Serving APIs](https://cloud.google.com/vertex-ai/docs/reference/rpc/google.cloud.aiplatform.v1beta1#featurestoreonlineservingservice)\n",
    "lets you serve feature values for small batches of entities. It's designed for latency-sensitive service, such as online model prediction. For example, for a movie service, you might want to quickly show movies that the current user would most likely watch by using online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foNB0D2aw37c"
   },
   "source": [
    "### Read one entity per request\n",
    "\n",
    "The `ReadFeatureValues` API is used to read feature values of one entity; hence\n",
    "its custom HTTP verb is `readFeatureValues`. By default, the API will return the  latest value of each feature, meaning the feature values with the most recent  timestamp.\n",
    "\n",
    "To read feature values, specify the entity ID and features to read. The response\n",
    "contains a `header` and an `entity_view`. Each row of data in the `entity_view`\n",
    "contains one feature value, in the same order of features as listed in the response header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3rfWqLrbXjnJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureSelector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24065/2028086668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fetch the following 3 features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m feature_selector = FeatureSelector(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mid_matcher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIdMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"liked_genres\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureSelector' is not defined"
     ]
    }
   ],
   "source": [
    "# Fetch the following 3 features.\n",
    "feature_selector = FeatureSelector(\n",
    "    id_matcher=IdMatcher(ids=[\"age\", \"gender\", \"liked_genres\"])\n",
    ")\n",
    "\n",
    "data_client.read_feature_values(\n",
    "    featurestore_online_service_pb2.ReadFeatureValuesRequest(\n",
    "        # Fetch from the following feature store/entity type\n",
    "        entity_type=admin_client.entity_type_path(\n",
    "            PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
    "        ),\n",
    "        # Fetch the user features whose ID is \"alice\"\n",
    "        entity_id=\"alice\",\n",
    "        feature_selector=feature_selector,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYk83Zt9xF8m"
   },
   "source": [
    "### Read multiple entities per request\n",
    "\n",
    "To read feature values from multiple entities, use the\n",
    "`StreamingReadFeatureValues` API, which is almost identical to the previous\n",
    "`ReadFeatureValues` API. Note that fetching only a small number of entities is recomended when using this API due to its latency-sensitive nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "BIJFcIIHULOd"
   },
   "outputs": [],
   "source": [
    "# Read the same set of features as above, but for multiple entities.\n",
    "response_stream = data_client.streaming_read_feature_values(\n",
    "    featurestore_online_service_pb2.StreamingReadFeatureValuesRequest(\n",
    "        entity_type=admin_client.entity_type_path(\n",
    "            PROJECT_ID, REGION, FEATURESTORE_ID, \"users\"\n",
    "        ),\n",
    "        entity_ids=[\"alice\", \"bob\"],\n",
    "        feature_selector=feature_selector,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NFrVLiHyUj2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header {\n",
      "  entity_type: \"projects/974758944585/locations/us-central1/featurestores/movie_prediction/entityTypes/users\"\n",
      "  feature_descriptors {\n",
      "    id: \"age\"\n",
      "  }\n",
      "  feature_descriptors {\n",
      "    id: \"gender\"\n",
      "  }\n",
      "  feature_descriptors {\n",
      "    id: \"liked_genres\"\n",
      "  }\n",
      "}\n",
      "\n",
      "entity_view {\n",
      "  entity_id: \"alice\"\n",
      "  data {\n",
      "    value {\n",
      "      int64_value: 55\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1629493102\n",
      "          nanos: 261000000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      string_value: \"Female\"\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1629493102\n",
      "          nanos: 261000000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      string_array_value {\n",
      "        values: \"Drama\"\n",
      "      }\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1629493102\n",
      "          nanos: 261000000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "entity_view {\n",
      "  entity_id: \"bob\"\n",
      "  data {\n",
      "    value {\n",
      "      int64_value: 35\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1629493102\n",
      "          nanos: 261000000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      string_value: \"Male\"\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1629493102\n",
      "          nanos: 261000000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  data {\n",
      "    value {\n",
      "      string_array_value {\n",
      "        values: \"Action\"\n",
      "        values: \"Adventure\"\n",
      "      }\n",
      "      metadata {\n",
      "        generate_time {\n",
      "          seconds: 1629493102\n",
      "          nanos: 261000000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate and process response. Note the first one is always the header only.\n",
    "for response in response_stream:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sds42j8ZsCzS"
   },
   "source": [
    "Now that you have learned how to fetch imported feature values for online serving, the next step is learning how to use imported feature values for offline use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpvhPAYxD-Ml"
   },
   "source": [
    "## Batch Serving\n",
    "\n",
    "Batch Serving is used to fetch a large batch of feature values for high-throughput, typically for training a model or batch prediction. In this section, you will learn how to prepare for training examples by calling the `BatchReadFeatureValues` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPzAGvqJHh3B"
   },
   "source": [
    "### Use case\n",
    "\n",
    "**The task** is to prepare a training dataset to train a model, which predicts if a given user will watch a given movie. To achieve this, you need 2 sets of input:\n",
    "\n",
    "*   Features: you already imported into the featurestore.\n",
    "*   Labels: the groud-truth data recorded that user X has watched movie Y.\n",
    "\n",
    "\n",
    "To be more specific, the ground-truth observation is described in Table 1 and the desired training dataset is described in Table 2. Each row in Table 2 is a result of joining the imported feature values from Feature Store according to the entity IDs and timestamps in Table 1. In this example,  the `age`, `gender` and `liked_genres` features from `users` and\n",
    "the `genres` and `average_rating` features from `movies` are chosen to train the model. Note that only positive examples are shown in these 2 tables, i.e., you can imagine there is a label column whose values are all `True`.\n",
    "\n",
    "`BatchReadFeatureValues` API takes Table 1 as\n",
    "input, joins all required feature values from the featurestore, and returns Table 2 for training.\n",
    "\n",
    "<h4 align=\"center\">Table 1. Ground-truth Data</h4>\n",
    "\n",
    "users | movies | timestamp            \n",
    "----- | -------- | -------------------- \n",
    "alice  | Cinema Paradiso     | 2019-11-01T00:00:00Z \n",
    "bob  | The Shining     | 2019-11-15T18:09:43Z \n",
    "...   | ...      | ...     \n",
    "\n",
    "\n",
    "<h4 align=\"center\">Table 2. Expected Training Data Generated by Batch Read API (Positive Samples)</h4>\n",
    "\n",
    "timestamp            | entity_type_users | age | gender | liked_genres | entity_type_movies | genres | average_rating  \n",
    "-------------------- | ----------------- | --------------- | ---------------- | -------------------- | -------- | --------- | ----- \n",
    "2019-11-01T00:00:00Z | bob              | 35        | M                | [Action, Crime]                 | The Shining | Horror | 4.8 \n",
    "2019-11-01T00:00:00Z | alice             | 55        | F                | [Drama, Comedy]                 | Cinema Paradiso | Romance | 4.5 \n",
    "... | ... | ... | ... | ... | ... | ... | ... \n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKwWGg2i4a4G"
   },
   "source": [
    "#### Why timestamp?\n",
    "\n",
    "Note that there is a `timestamp` column in Table 2. This indicates the time when the ground-truth was observed. This is to avoid data inconsistency.\n",
    "\n",
    "For example, the 1st row of Table 2 indicates that user `alice` watched movie `Cinema Paradiso` on `2019-11-01T00:00:00Z`. The featurestore keeps feature values for all timestamps but fetches feature values *only* at the given timestamp during batch serving. On 2019-11-01 alice might be 54 years old, but now alice might be 56; the featurestore returns `age=54` as alice's age, instead of `age=56`, because that is the value of the feature at the observation time. Similarly, other features might be time-variant as well, such as `liked_genres`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8dLJ9nuDFgI"
   },
   "source": [
    "### Batch Read Feature Values\n",
    "\n",
    "Assemble the request which specifies the following info:\n",
    "\n",
    "*   Where is the label data, i.e., Table 1.\n",
    "*   Which features are read, i.e., the column names in Table 2.\n",
    "\n",
    "The output is stored in a BigQuery table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7IyoXHY2ECnh"
   },
   "outputs": [],
   "source": [
    "batch_serving_request = featurestore_service_pb2.BatchReadFeatureValuesRequest(\n",
    "    # featurestore info\n",
    "    featurestore=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
    "    # URL for the label data, i.e., Table 1.\n",
    "    csv_read_instances=io_pb2.CsvSource(\n",
    "        gcs_source=io_pb2.GcsSource(uris=[INPUT_CSV_FILE])\n",
    "    ),\n",
    "    destination=featurestore_service_pb2.FeatureValueDestination(\n",
    "        bigquery_destination=io_pb2.BigQueryDestination(\n",
    "            # Output to BigQuery table created earlier\n",
    "            output_uri=DESTINATION_TABLE_URI\n",
    "        )\n",
    "    ),\n",
    "    entity_type_specs=[\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
    "            # Read the 'age', 'gender' and 'liked_genres' features from the 'users' entity\n",
    "            entity_type_id=\"users\",\n",
    "            feature_selector=FeatureSelector(\n",
    "                id_matcher=IdMatcher(\n",
    "                    ids=[\n",
    "                        # features, use \"*\" if you want to select all features within this entity type\n",
    "                        \"age\",\n",
    "                        \"gender\",\n",
    "                        \"liked_genres\",\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        featurestore_service_pb2.BatchReadFeatureValuesRequest.EntityTypeSpec(\n",
    "            # Read the 'average_rating' and 'genres' feature values of the 'movies' entity\n",
    "            entity_type_id=\"movies\",\n",
    "            feature_selector=FeatureSelector(\n",
    "                id_matcher=IdMatcher(ids=[\"average_rating\", \"genres\"])\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "bZO5sRCfEEWn"
   },
   "outputs": [],
   "source": [
    "# Execute the batch read\n",
    "batch_serving_lro = admin_client.batch_read_feature_values(batch_serving_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ouMiJqh-EFlh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This long runing operation will poll until the batch read finishes.\n",
    "batch_serving_lro.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RAdjahHQ93J"
   },
   "source": [
    "After the LRO finishes, you should be able to see the result from the [BigQuery console](https://console.cloud.google.com/bigquery), in the dataset created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "You can also keep the project but delete the featurestore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a2WfqhbFzQBF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted dataset 'movie_predictions_20211007204042'.\n"
     ]
    }
   ],
   "source": [
    "admin_client.delete_featurestore(\n",
    "    request=featurestore_service_pb2.DeleteFeaturestoreRequest(\n",
    "        name=admin_client.featurestore_path(PROJECT_ID, REGION, FEATURESTORE_ID),\n",
    "        force=True,\n",
    "    )\n",
    ").result()\n",
    "client.delete_dataset(\n",
    "    DESTINATION_DATA_SET, delete_contents=True, not_found_ok=True\n",
    ")  # Make an API request.\n",
    "\n",
    "print(\"Deleted dataset '{}'.\".format(DESTINATION_DATA_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ze4-nDLfK4pw"
   ],
   "name": "gapic-feature-store.ipynb",
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
