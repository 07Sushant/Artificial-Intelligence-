{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b00d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b87f40",
   "metadata": {},
   "source": [
    "# Predict with JAX/Flax-trained SavedModel on Vertex AI custom container with TF Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad39380",
   "metadata": {},
   "source": [
    "Vertex AI Prediction supports pre-built containers, with no additional customization such as args (\"Do not specify any other subfields of containerSpec\" [source](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#using_a_pre-built_container)), and custom containers. As we need the `--xla_cpu_compilation_enabled` arg, we can only use custom containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8278f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import flags\n",
    "from google.cloud import aiplatform\n",
    "from jax.experimental.jax2tf.examples.mnist_lib import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d35db",
   "metadata": {},
   "source": [
    "## Create TFServing container with SavedModel baked in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c5a73",
   "metadata": {},
   "source": [
    "NOTE: serving does not work for GPU yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea806a",
   "metadata": {},
   "source": [
    "Below, `SAVEDMODELDIR` should point to a model created in [training-prebuilt.ipynb](training-prebuilt.ipynb). Change it to any directory containing a SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4317f94",
   "metadata": {
    "tags": [
     "flake8-noqa-line-1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcr.io/dsparing-sandbox/jax_tfserving_image:latest-cpu\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "BUCKET_NAME = \"dsparing-sandbox-bucket\"\n",
    "os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
    "\n",
    "MODEL_NAME = \"jax_model_prebuilt\"\n",
    "\n",
    "SAVEDMODEL_DIR = (f\"gs://{BUCKET_NAME}/models/\"\n",
    "                  f\"{MODEL_NAME}/output/model\")\n",
    "\n",
    "SERVING_MODELNAME = \"jax_model\"\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "USE_GPU = False\n",
    "if USE_GPU:\n",
    "    IMAGE_TAG = \"latest-gpu\"\n",
    "    TFSERVING_TAG = \"latest-gpu\"\n",
    "else:\n",
    "    IMAGE_TAG = \"latest-cpu\"\n",
    "    TFSERVING_TAG = \"latest\"\n",
    "\n",
    "IMAGE_NAME = \"jax_tfserving_image\"\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{IMAGE_TAG}\"\n",
    "print(IMAGE_URI)\n",
    "\n",
    "os.environ[\"SERVING_MODELNAME\"] = SERVING_MODELNAME\n",
    "os.environ[\"SAVEDMODEL_DIR\"] = SAVEDMODEL_DIR\n",
    "os.environ[\"MODEL_VERSION\"] = str(MODEL_VERSION)\n",
    "os.environ[\"IMAGE_URI\"] = IMAGE_URI\n",
    "os.environ[\"IMAGE_TAG\"] = IMAGE_TAG\n",
    "os.environ[\"TFSERVING_TAG\"] = TFSERVING_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667e0af",
   "metadata": {},
   "source": [
    "Check that `SAVEDMODEL_DIR` actually contains a SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c93744f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/saved_model.pb\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/assets/\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls $SAVEDMODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97c931e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/saved_model.pb...\n",
      "Copying gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/saved_model.pb...\n",
      "/ [2 files][ 86.3 KiB/ 86.3 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/variables.data-00000-of-00001...\n",
      "Copying gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/variables.index...\n",
      "- [4 files][  3.2 MiB/  3.2 MiB]                                                \n",
      "Operation completed over 4 objects/3.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp -r $SAVEDMODEL_DIR/* $SAVEDMODEL_DIR/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ac9ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/saved_model.pb\n",
      "\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/:\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/saved_model.pb\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/1/\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/variables/\n",
      "\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/assets/:\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/assets/\n",
      "\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/:\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/variables.data-00000-of-00001\n",
      "gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls $SAVEDMODEL_DIR/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2faf1a0",
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p $SERVING_MODELNAME/$MODEL_VERSION # tf serving wants model versions in numbered directories.\n",
    "gsutil -q cp -r $SAVEDMODEL_DIR/* $SERVING_MODELNAME/$MODEL_VERSION/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd01d15",
   "metadata": {},
   "source": [
    "Below we follow the [TF Serving tutorial](https://www.tensorflow.org/tfx/serving/docker#creating_your_own_serving_image) for creating your own serving image with the model baked in. We spin up a TF Serving container, copy the model inside the container, and commit this change together with the `MODEL_NAME` environment variable. After the commit, the base TF Serving container can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df5253a",
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d962ca3b1475655da79a303881a3666165ef29a38e74c99635b872322b158060\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run -d --name serving_base tensorflow/serving:$TFSERVING_TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3047f3",
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:0149676bf3240ab13fad895cd1b5b5874209db084c9412a77b78273be6b07f7a\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker cp $SERVING_MODELNAME serving_base:/models/$SERVING_MODELNAME\n",
    "docker commit --change \"ENV MODEL_NAME $SERVING_MODELNAME\" serving_base $IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1832c1",
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving_base\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker rm -f serving_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5c687",
   "metadata": {},
   "source": [
    "## Try serving locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ec7d7",
   "metadata": {},
   "source": [
    "Get image to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6203bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/jupyter/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split test, from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "# need to initialize flags somehow to avoid errors in load_mnist\n",
    "flags.FLAGS(['e'])\n",
    "\n",
    "image_to_predict, _ = next(iter(load_mnist(tfds.Split.TEST, batch_size=1)))\n",
    "instances = image_to_predict.numpy().tolist()\n",
    "image_json = json.dumps(instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c646256",
   "metadata": {},
   "source": [
    "Start up container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9463d7d6",
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938c6cadafb0566de144f7b8880e1112201d6994c763b85bf9f26f1911a847b3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run -d -p 8501:8501 -e MODEL_NAME=$SERVING_MODELNAME --name serving_jax \\\n",
    "    tensorflow/serving:$TFSERVING_TAG --xla_cpu_compilation_enabled=true \\\n",
    "        --model_base_path=\"gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1a2a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-27 01:59:21.819077: I tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: jax_model model_base_path: gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/\n",
      "2021-06-27 01:59:21.819343: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
      "2021-06-27 01:59:21.819378: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: jax_model\n",
      "2021-06-27 01:59:23.395493: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: jax_model version: 1}\n",
      "2021-06-27 01:59:23.395525: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: jax_model version: 1}\n",
      "2021-06-27 01:59:23.395557: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: jax_model version: 1}\n",
      "2021-06-27 01:59:23.534478: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1\n",
      "2021-06-27 01:59:23.713910: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2021-06-27 01:59:23.713963: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1\n",
      "2021-06-27 01:59:23.844537: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-27 01:59:23.880162: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-06-27 01:59:23.881065: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2299995000 Hz\n",
      "2021-06-27 01:59:24.692213: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1\n",
      "2021-06-27 01:59:24.697805: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 1163328 microseconds.\n",
      "2021-06-27 01:59:24.834432: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at gs://dsparing-sandbox-bucket/models/jax_model_prebuilt/output/model/1/assets.extra/tf_serving_warmup_requests\n",
      "2021-06-27 01:59:25.671794: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: jax_model version: 1}\n",
      "2021-06-27 01:59:25.672792: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
      "2021-06-27 01:59:25.672863: I tensorflow_serving/model_servers/server.cc:367] Profiler service is enabled\n",
      "2021-06-27 01:59:25.674226: I tensorflow_serving/model_servers/server.cc:393] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2021-06-27 01:59:25.676764: I tensorflow_serving/model_servers/server.cc:414] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sleep 2\n",
    "docker logs serving_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fe7ac",
   "metadata": {},
   "source": [
    "Send prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d78e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.4188423, -0.00523996353, -8.44263649, -7.61883926, -10.9973564, -9.40729, -8.70840836, -10.2604904, -5.51396084, -8.56981277]]\n"
     ]
    }
   ],
   "source": [
    "data = json.dumps({\"instances\": image_to_predict.numpy().tolist()})\n",
    "json_response = requests.post(\n",
    "    f'http://localhost:8501/v1/models/{SERVING_MODELNAME}:predict',\n",
    "    data=data,\n",
    ")\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21365d1d",
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving_jax\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker rm -f serving_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1c50e",
   "metadata": {},
   "source": [
    "## Push image to Container Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313ea0d",
   "metadata": {},
   "source": [
    "## Upload prediction container to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec12c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "\n",
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "\n",
    "if USE_GPU:\n",
    "    MODEL_DISPLAYNAME = f\"{SERVING_MODELNAME}-gpu\"\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "else:\n",
    "    MODEL_DISPLAYNAME = f\"{SERVING_MODELNAME}-cpu\"\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAYNAME,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    "    serving_container_predict_route=f\"/v1/models/{SERVING_MODELNAME}:predict\",\n",
    "    serving_container_health_route=f\"/v1/models/{SERVING_MODELNAME}\",\n",
    "    serving_container_args=['--xla_cpu_compilation_enabled=true'],\n",
    "    serving_container_ports=[8501],\n",
    ")\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f54022",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb67af2",
   "metadata": {},
   "source": [
    "## Get Online Predictions from Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16304bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances)\n",
    "print(prediction.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d5099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
