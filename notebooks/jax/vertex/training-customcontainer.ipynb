{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train JAX/Flax model on Vertex AI custom container and use `jax2tf` to convert to SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runs on TF2.5 [Vertex Notebook](https://cloud.google.com/vertex-ai/docs/general/notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v-kebtVqdEyV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W-IAEp1UqmKR"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "BUCKET_NAME = \"dsparing-sandbox-bucket\"\n",
    "os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
    "\n",
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "os.environ['TRAINING_APP_FOLDER'] = TRAINING_APP_FOLDER\n",
    "\n",
    "MODEL_NAME = \"jax_model\"\n",
    "MODEL_DIR = f\"gs://{BUCKET_NAME}/models/{MODEL_NAME}\"\n",
    "os.environ['MODEL_DIR'] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p $TRAINING_APP_FOLDER/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_app/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/trainer/task.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from absl import flags\n",
    "from jax.experimental.jax2tf.examples.mnist_lib import load_mnist, FlaxMNIST\n",
    "from jax.experimental.jax2tf.examples.saved_model_lib import convert_and_save_model\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"GCS location to export SavedModel\",\n",
    "        default = os.getenv(\"AIP_MODEL_DIR\")\n",
    "    )\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    \n",
    "    flags.FLAGS(['e']) # need to initialize flags somehow to avoid errors in load_mnist\n",
    "\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 16\n",
    "\n",
    "\n",
    "    flax_mnist = FlaxMNIST()\n",
    "\n",
    "    train_ds = load_mnist(tfds.Split.TRAIN, train_batch_size)\n",
    "    test_ds = load_mnist(tfds.Split.TEST, test_batch_size)\n",
    "\n",
    "    predict_fn, params = flax_mnist.train(\n",
    "        train_ds=train_ds,\n",
    "        test_ds=test_ds,\n",
    "        num_epochs=2\n",
    "    )\n",
    "\n",
    "    image, _ = next(iter(train_ds))\n",
    "    input_signature = tf.TensorSpec.from_tensor(tf.expand_dims(image[0], axis=0))\n",
    "\n",
    "    convert_and_save_model(\n",
    "        jax_fn=predict_fn,\n",
    "        params=params,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        input_signatures=[input_signature],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to use [CustomContainerTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomContainerTrainingJob), but it gives an error, see the similar [CustomTrainingJob.run](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob.run) currently giving an error even when using the [official notebook](https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/official/custom/sdk-custom-image-classification-online.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'n1-standard-4'\n",
    "REPLICA_COUNT = 1\n",
    "JOB_NAME = 'jax_customcontainer_training'\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    TRAINING_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "    IMAGE_NAME='jax_vertex_image_gpu'\n",
    "else:\n",
    "    TRAINING_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-cpu.2-5'\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None\n",
    "    IMAGE_NAME='jax_vertex_image_cpu'\n",
    "\n",
    "os.environ['TRAINING_IMAGE'] = TRAINING_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1617197650331,
     "user": {
      "displayName": "Daniel Sparing",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimB4WP4BC_SgKVqyvIS8u7WFJXnJGMSuyFNS4Lww=s64",
      "userId": "02797666024167492243"
     },
     "user_tz": 300
    },
    "id": "WlzDz-6wdpNC",
    "outputId": "9404061c-e26c-42e3-9b2a-bce48767be1f"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo > $TRAINING_APP_FOLDER/Dockerfile \"FROM $TRAINING_IMAGE\n",
    "RUN python -m pip install -U jax jaxlib==0.1.67+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html \n",
    "RUN python -m pip install -U flax \n",
    "WORKDIR /app\n",
    "COPY trainer/task.py .\n",
    "\n",
    "ENTRYPOINT [\\\"python\\\", \\\"task.py\\\"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FZ7Eh2Wwfc9Y"
   },
   "outputs": [],
   "source": [
    "IMAGE_TAG = 'latest'\n",
    "IMAGE_URI = 'gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, IMAGE_TAG)\n",
    "os.environ['IMAGE_URI'] = IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1617197720314,
     "user": {
      "displayName": "Daniel Sparing",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimB4WP4BC_SgKVqyvIS8u7WFJXnJGMSuyFNS4Lww=s64",
      "userId": "02797666024167492243"
     },
     "user_tz": 300
    },
    "id": "JhHx_WUIfs6j",
    "outputId": "418935e1-58c0-4812-f820-c09244711048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  35.84kB\n",
      "Step 1/6 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-5\n",
      " ---> 950969e5619c\n",
      "Step 2/6 : RUN python -m pip install -U jax jaxlib==0.1.67+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
      " ---> Using cache\n",
      " ---> 62b0407dec24\n",
      "Step 3/6 : RUN python -m pip install -U flax\n",
      " ---> Using cache\n",
      " ---> 8424950476a1\n",
      "Step 4/6 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> fc9e144a502a\n",
      "Step 5/6 : COPY trainer/task.py .\n",
      " ---> Using cache\n",
      " ---> 5a8d67bded7d\n",
      "Step 6/6 : ENTRYPOINT [\"python\", \"task.py\"]\n",
      " ---> Using cache\n",
      " ---> 51dc3109ad96\n",
      "Successfully built 51dc3109ad96\n",
      "Successfully tagged gcr.io/dsparing-sandbox/jax_vertex_image_gpu:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker build -f $TRAINING_APP_FOLDER/Dockerfile --tag $IMAGE_URI $TRAINING_APP_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/dsparing-sandbox/jax_vertex_image_gpu:latest'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional local test:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "error",
     "timestamp": 1617776619162,
     "user": {
      "displayName": "Daniel Sparing",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimB4WP4BC_SgKVqyvIS8u7WFJXnJGMSuyFNS4Lww=s64",
      "userId": "02797666024167492243"
     },
     "user_tz": 300
    },
    "id": "X0rCYgF6_63Y",
    "outputId": "8d917d99-39db-4ae9-cefc-ed5b6ad74289"
   },
   "source": [
    "%%bash\n",
    "docker run --name training_jax $IMAGE_URI --output_dir=$MODEL_DIR # --xla_cpu_compilation_enabled=true --runtime=nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once the above container run finished:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "docker rm -f training_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push image to registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: name: \"projects/654544512569/locations/us-central1/customJobs/6638415801906888704\"\n",
      "display_name: \"jax_customcontainer_training\"\n",
      "job_spec {\n",
      "  worker_pool_specs {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "      accelerator_type: NVIDIA_TESLA_T4\n",
      "      accelerator_count: 1\n",
      "    }\n",
      "    replica_count: 1\n",
      "    disk_spec {\n",
      "      boot_disk_type: \"pd-ssd\"\n",
      "      boot_disk_size_gb: 100\n",
      "    }\n",
      "    container_spec {\n",
      "      image_uri: \"gcr.io/dsparing-sandbox/jax_vertex_image_gpu:latest\"\n",
      "      args: \"--output_dir=gs://dsparing-sandbox-bucket/models/jax_model\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "state: JOB_STATE_PENDING\n",
      "create_time {\n",
      "  seconds: 1624287896\n",
      "  nanos: 263811000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1624287896\n",
      "  nanos: 263811000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "api_endpoint: str = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "\n",
    "# The AI Platform services require regional API endpoints.\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "# Initialize client that will be used to create and send requests.\n",
    "# This client only needs to be created once, and can be reused for multiple requests.\n",
    "client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "custom_job = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": {\n",
    "        \"worker_pool_specs\": [\n",
    "            {\n",
    "                \"machine_spec\": {\n",
    "                    \"machine_type\": MACHINE_TYPE,\n",
    "                    \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "                    \"accelerator_count\": ACCELERATOR_COUNT,\n",
    "                },\n",
    "                \"replica_count\": REPLICA_COUNT,\n",
    "                \"container_spec\": {\n",
    "                    \"image_uri\": IMAGE_URI,\n",
    "                    \"args\": [\n",
    "                        \"--output_dir=\" + MODEL_DIR,\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "response = client.create_custom_job(parent=parent, custom_job=custom_job)\n",
    "print(\"response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_state = client.get_custom_job(name=response.name).state\n",
    "    print(job_state)\n",
    "    if job_state not in (aiplatform_v1.JobState.JOB_STATE_QUEUED, aiplatform_v1.JobState.JOB_STATE_PENDING, aiplatform_v1.JobState.JOB_STATE_RUNNING):\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure we can actually predict with savedmodel (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 install --user --upgrade jax jaxlib==0.1.67+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-18T01:17:21Z  gs://dsparing-sandbox-bucket/models/jax_model/\n",
      "     54003  2021-06-21T15:15:10Z  gs://dsparing-sandbox-bucket/models/jax_model/saved_model.pb\n",
      "                                 gs://dsparing-sandbox-bucket/models/jax_model/assets/\n",
      "                                 gs://dsparing-sandbox-bucket/models/jax_model/variables/\n",
      "TOTAL: 2 objects, 54003 bytes (52.74 KiB)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls -l $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/jupyter/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split test, from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "from jax.experimental.jax2tf.examples.mnist_lib import load_mnist\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "flags.FLAGS(['e']) # need to initialize flags somehow to avoid errors in load_mnist\n",
    "\n",
    "image_to_predict, _ = next(iter(load_mnist(tfds.Split.TEST, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[ -6.717919  , -14.699879  ,  -1.9437121 ,  -3.6636014 ,\n",
       "          -7.9636226 ,  -9.026531  , -10.630737  ,  -0.21502149,\n",
       "          -5.097106  ,  -4.083507  ]], dtype=float32)>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(MODEL_DIR)\n",
    "loaded_model.signatures[\"serving_default\"](image_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "JAX Flax MNIST containerize",
   "provenance": [
    {
     "file_id": "1HenHxSnSqNQPqMPZNG_uhFampEPxN_Cj",
     "timestamp": 1617196427779
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
