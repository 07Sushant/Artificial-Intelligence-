{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train JAX/Flax model on Vertex AI custom container and use `jax2tf` to convert to SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runs on TF2.5 [Vertex Notebook](https://cloud.google.com/vertex-ai/docs/general/notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v-kebtVqdEyV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W-IAEp1UqmKR"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "BUCKET_NAME = \"dsparing-sandbox-bucket\"\n",
    "os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
    "\n",
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "os.environ['TRAINING_APP_FOLDER'] = TRAINING_APP_FOLDER\n",
    "\n",
    "MODEL_NAME = \"jax_model\"\n",
    "MODEL_DIR = f\"gs://{BUCKET_NAME}/models/{MODEL_NAME}\"\n",
    "os.environ['MODEL_DIR'] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p $TRAINING_APP_FOLDER/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_app/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/trainer/task.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from absl import flags\n",
    "from jax.experimental.jax2tf.examples.mnist_lib import (\n",
    "    load_mnist, FlaxMNIST\n",
    ")\n",
    "from jax.experimental.jax2tf.examples.saved_model_lib import (\n",
    "    convert_and_save_model\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"GCS location to export SavedModel\",\n",
    "        default=os.getenv(\"AIP_MODEL_DIR\")\n",
    "    )\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    # need to initialize flags somehow to avoid errors in load_mnist\n",
    "    flags.FLAGS(['e'])\n",
    "\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 16\n",
    "\n",
    "    flax_mnist = FlaxMNIST()\n",
    "\n",
    "    train_ds = load_mnist(tfds.Split.TRAIN, train_batch_size)\n",
    "    test_ds = load_mnist(tfds.Split.TEST, test_batch_size)\n",
    "\n",
    "    predict_fn, params = flax_mnist.train(\n",
    "        train_ds=train_ds,\n",
    "        test_ds=test_ds,\n",
    "        num_epochs=2\n",
    "    )\n",
    "\n",
    "    image, _ = next(iter(train_ds))\n",
    "    input_signature = tf.TensorSpec.from_tensor(\n",
    "        tf.expand_dims(image[0], axis=0)\n",
    "    )\n",
    "\n",
    "    convert_and_save_model(\n",
    "        jax_fn=predict_fn,\n",
    "        params=params,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        input_signatures=[input_signature],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to use [CustomContainerTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomContainerTrainingJob), but it gives an error, see the similar [CustomTrainingJob.run](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob.run) currently giving an error even when using the [official notebook](https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/official/custom/sdk-custom-image-classification-online.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = 'n1-standard-4'\n",
    "REPLICA_COUNT = 1\n",
    "JOB_NAME = 'jax_customcontainer_training'\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    TRAINING_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "    IMAGE_NAME = 'jax_vertex_image_gpu'\n",
    "else:\n",
    "    TRAINING_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-cpu.2-5'\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None\n",
    "    IMAGE_NAME = 'jax_vertex_image_cpu'\n",
    "\n",
    "os.environ['TRAINING_IMAGE'] = TRAINING_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/requirements.txt\n",
    "flax\n",
    "jax[cuda111]  # needs pip to run with `-f https://storage.googleapis.com/jax-releases/jax_releases.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1617197650331,
     "user": {
      "displayName": "Daniel Sparing",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimB4WP4BC_SgKVqyvIS8u7WFJXnJGMSuyFNS4Lww=s64",
      "userId": "02797666024167492243"
     },
     "user_tz": 300
    },
    "id": "WlzDz-6wdpNC",
    "outputId": "9404061c-e26c-42e3-9b2a-bce48767be1f",
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo > $TRAINING_APP_FOLDER/Dockerfile \"FROM $TRAINING_IMAGE\n",
    "RUN python3 -m pip install --no-cache-dir -r requirements.txt -f https://storage.googleapis.com/jax-releases/jax_releases.html \n",
    "WORKDIR /app\n",
    "COPY trainer/task.py .\n",
    "\n",
    "ENTRYPOINT [\\\"python\\\", \\\"task.py\\\"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FZ7Eh2Wwfc9Y"
   },
   "outputs": [],
   "source": [
    "IMAGE_TAG = 'latest'\n",
    "IMAGE_URI = 'gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, IMAGE_TAG)\n",
    "os.environ['IMAGE_URI'] = IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1617197720314,
     "user": {
      "displayName": "Daniel Sparing",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimB4WP4BC_SgKVqyvIS8u7WFJXnJGMSuyFNS4Lww=s64",
      "userId": "02797666024167492243"
     },
     "user_tz": 300
    },
    "id": "JhHx_WUIfs6j",
    "outputId": "418935e1-58c0-4812-f820-c09244711048"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker build -f $TRAINING_APP_FOLDER/Dockerfile \\\n",
    "--tag $IMAGE_URI $TRAINING_APP_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional local test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "error",
     "timestamp": 1617776619162,
     "user": {
      "displayName": "Daniel Sparing",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimB4WP4BC_SgKVqyvIS8u7WFJXnJGMSuyFNS4Lww=s64",
      "userId": "02797666024167492243"
     },
     "user_tz": 300
    },
    "id": "X0rCYgF6_63Y",
    "outputId": "8d917d99-39db-4ae9-cefc-ed5b6ad74289"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run --name training_jax $IMAGE_URI --output_dir=$MODEL_DIR # --xla_cpu_compilation_enabled=true --runtime=nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once the above container run finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker rm -f training_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push image to registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_endpoint: str = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "\n",
    "# The AI Platform services require regional API endpoints.\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "# Initialize client that will be used to create and send requests.\n",
    "# This client only needs to be created once, and can be reused for multiple\n",
    "# requests.\n",
    "client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "custom_job = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": {\n",
    "        \"worker_pool_specs\": [\n",
    "            {\n",
    "                \"machine_spec\": {\n",
    "                    \"machine_type\": MACHINE_TYPE,\n",
    "                    \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "                    \"accelerator_count\": ACCELERATOR_COUNT,\n",
    "                },\n",
    "                \"replica_count\": REPLICA_COUNT,\n",
    "                \"container_spec\": {\n",
    "                    \"image_uri\": IMAGE_URI,\n",
    "                    \"args\": [\n",
    "                        \"--output_dir=\" + MODEL_DIR,\n",
    "                    ]\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "response = client.create_custom_job(parent=parent, custom_job=custom_job)\n",
    "print(\"response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    job_state = client.get_custom_job(name=response.name).state\n",
    "    print(job_state)\n",
    "    if job_state not in (\n",
    "        aiplatform_v1.JobState.JOB_STATE_QUEUED,\n",
    "        aiplatform_v1.JobState.JOB_STATE_PENDING,\n",
    "        aiplatform_v1.JobState.JOB_STATE_RUNNING\n",
    "    ):\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure we can actually predict with savedmodel (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil ls -l $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.jax2tf.examples.mnist_lib import load_mnist\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "# need to initialize flags somehow to avoid errors in load_mnist\n",
    "flags.FLAGS(['e'])\n",
    "\n",
    "image_to_predict, _ = next(iter(load_mnist(tfds.Split.TEST, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(MODEL_DIR)\n",
    "loaded_model.signatures[\"serving_default\"](image_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "JAX Flax MNIST containerize",
   "provenance": [
    {
     "file_id": "1HenHxSnSqNQPqMPZNG_uhFampEPxN_Cj",
     "timestamp": 1617196427779
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
