{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train JAX/Flax model on Vertex AI pre-built container and use `jax2tf` to convert to SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runs on TF2.5 [Vertex Notebook](https://cloud.google.com/vertex-ai/docs/general/notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v-kebtVqdEyV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from jax.experimental.jax2tf.examples.mnist_lib import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W-IAEp1UqmKR",
    "tags": [
     "flake8-noqa-line-1"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "BUCKET_NAME = \"dsparing-sandbox-bucket\"\n",
    "os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
    "\n",
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "os.environ['TRAINING_APP_FOLDER'] = TRAINING_APP_FOLDER\n",
    "\n",
    "MODEL_NAME = \"jax_model\"\n",
    "MODEL_DIR = f\"gs://{BUCKET_NAME}/models/{MODEL_NAME}\"\n",
    "os.environ['MODEL_DIR'] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p $TRAINING_APP_FOLDER/trainer\n",
    "touch $TRAINING_APP_FOLDER/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no pre-built Vertex TF2.5 container yet, and `jax.experimental.jax2tf.examples.saved_model_lib.convert_and_save_model` uses the `jit_compile` argument for `tf.function`, which is the TF2.5 new name for `experimental_compile`. So we define a copy `./saved_model_lib_tf24.py` of that module with the only difference that jit_compile is still called `experimental_compile` for TF2.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp saved_model_lib_tf24.py $TRAINING_APP_FOLDER/trainer/saved_model_lib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no pre-built Vertex TF2.5 container yet, and jax2tf in jax==0.2.14 uses `tensorflow.compiler.tf2xla.conv(... preferred_element_type)` which is not there in TF2.4, only in TF2.5. We can avoid this though by using `convert_and_save_model( ... enable_xla=False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "flake8-noqa-line-1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training_app/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/trainer/task.py\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import flags\n",
    "from jax.experimental.jax2tf.examples.mnist_lib import (\n",
    "    load_mnist, FlaxMNIST\n",
    ")\n",
    "# from jax.experimental.jax2tf.examples.saved_model_lib import (\n",
    "#     convert_and_save_model\n",
    "# )\n",
    "\n",
    "from trainer.saved_model_lib import convert_and_save_model\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        help=\"GCS location to export SavedModel\",\n",
    "        default=os.getenv(\"AIP_MODEL_DIR\")\n",
    "    )\n",
    "    args = parser.parse_args().__dict__\n",
    "\n",
    "    # need to initialize flags somehow to avoid errors in load_mnist\n",
    "    flags.FLAGS(['e'])\n",
    "\n",
    "    train_batch_size = 128\n",
    "    test_batch_size = 16\n",
    "\n",
    "    flax_mnist = FlaxMNIST()\n",
    "\n",
    "    train_ds = load_mnist(tfds.Split.TRAIN, train_batch_size)\n",
    "    test_ds = load_mnist(tfds.Split.TEST, test_batch_size)\n",
    "\n",
    "    predict_fn, params = flax_mnist.train(\n",
    "        train_ds=train_ds,\n",
    "        test_ds=test_ds,\n",
    "        num_epochs=2\n",
    "    )\n",
    "\n",
    "    image, _ = next(iter(train_ds))\n",
    "    input_signature = tf.TensorSpec.from_tensor(\n",
    "        tf.expand_dims(image[0], axis=0)\n",
    "    )\n",
    "\n",
    "    convert_and_save_model(\n",
    "        jax_fn=predict_fn,\n",
    "        params=params,\n",
    "        model_dir=args[\"output_dir\"],\n",
    "        input_signatures=[input_signature],\n",
    "        enable_xla=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional local test:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/$TRAINING_APP_FOLDER\n",
    "python3 -m trainer.task --output_dir=$MODEL_DIR\n",
    "gsutil ls -l $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to use [CustomTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob) or [CustomPythonPackageTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomPythonPackageTrainingJob), but it gives an error, see the similar [CustomTrainingJob.run](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob.run) currently giving an error even when using the [official notebook](https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/official/custom/sdk-custom-image-classification-online.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training_app/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = ['flax', 'jax']\n",
    "\n",
    "setup(\n",
    "    name='jax_flax_trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='JAX/FLAX model training application.'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing requirements to jax_flax_trainer.egg-info/requires.txt\n",
      "writing jax_flax_trainer.egg-info/PKG-INFO\n",
      "writing top-level names to jax_flax_trainer.egg-info/top_level.txt\n",
      "writing dependency_links to jax_flax_trainer.egg-info/dependency_links.txt\n",
      "reading manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating jax_flax_trainer-0.1\n",
      "creating jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "creating jax_flax_trainer-0.1/trainer\n",
      "copying files to jax_flax_trainer-0.1...\n",
      "copying setup.py -> jax_flax_trainer-0.1\n",
      "copying jax_flax_trainer.egg-info/PKG-INFO -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/SOURCES.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/dependency_links.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/requires.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/top_level.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying trainer/__init__.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/saved_model_lib.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task.py -> jax_flax_trainer-0.1/trainer\n",
      "Writing jax_flax_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'jax_flax_trainer-0.1' (and everything under it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd $TRAINING_APP_FOLDER\n",
    "python ./setup.py sdist --formats=gztar\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil -q cp $TRAINING_APP_FOLDER/dist/jax_flax_trainer-0.1.tar.gz gs://$BUCKET_NAME/jax/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: name: \"projects/654544512569/locations/us-central1/customJobs/3457942079122964480\"\n",
      "display_name: \"jax_job\"\n",
      "job_spec {\n",
      "  worker_pool_specs {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "      accelerator_type: NVIDIA_TESLA_T4\n",
      "      accelerator_count: 1\n",
      "    }\n",
      "    replica_count: 1\n",
      "    disk_spec {\n",
      "      boot_disk_type: \"pd-ssd\"\n",
      "      boot_disk_size_gb: 100\n",
      "    }\n",
      "    python_package_spec {\n",
      "      executor_image_uri: \"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest\"\n",
      "      package_uris: \"gs://dsparing-sandbox-bucket/jax/jax_flax_trainer-0.1.tar.gz\"\n",
      "      package_uris: \"gs://jax-releases/cuda110/jaxlib-0.1.67+cuda110-cp37-none-manylinux2010_x86_64.whl\"\n",
      "      python_module: \"trainer.task\"\n",
      "    }\n",
      "  }\n",
      "  base_output_directory {\n",
      "    output_uri_prefix: \"gs://dsparing-sandbox-bucket/jax/output\"\n",
      "  }\n",
      "}\n",
      "state: JOB_STATE_PENDING\n",
      "create_time {\n",
      "  seconds: 1624694068\n",
      "  nanos: 708517000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1624694068\n",
      "  nanos: 708517000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "JOB_NAME = \"jax_job\"\n",
    "\n",
    "# Vertex AI machines to use for training\n",
    "JAXLIB_URI = \"gs://jax-releases/cuda110/jaxlib-0.1.67+cuda110-cp37-none-manylinux2010_x86_64.whl\"\n",
    "PYTHON_PACKAGE_URIS = [f\"gs://{BUCKET_NAME}/jax/jax_flax_trainer-0.1.tar.gz\", JAXLIB_URI]\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "REPLICA_COUNT = 1\n",
    "PYTHON_MODULE = \"trainer.task\"\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    TRAINING_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "else:\n",
    "    TRAINING_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-4:latest'\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None\n",
    "\n",
    "api_endpoint: str = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "\n",
    "# The AI Platform services require regional API endpoints.\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "# Initialize client that will be used to create and send requests.\n",
    "# This client only needs to be created once, and can be reused for multiple\n",
    "# requests.\n",
    "client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "custom_job = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": {\n",
    "        \"worker_pool_specs\": [\n",
    "            {\n",
    "                \"machine_spec\": {\n",
    "                    \"machine_type\": MACHINE_TYPE,\n",
    "                    \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "                    \"accelerator_count\": ACCELERATOR_COUNT,\n",
    "                },\n",
    "                \"replica_count\": REPLICA_COUNT,\n",
    "                \"python_package_spec\": {\n",
    "                    \"executor_image_uri\": TRAINING_IMAGE,\n",
    "                    \"package_uris\": PYTHON_PACKAGE_URIS,\n",
    "                    \"python_module\": PYTHON_MODULE,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        \"base_output_directory\": {\n",
    "            \"output_uri_prefix\": f\"gs://{BUCKET_NAME}/jax/output\"\n",
    "        },\n",
    "    },\n",
    "}\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "response = client.create_custom_job(parent=parent, custom_job=custom_job)\n",
    "print(\"response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_state = client.get_custom_job(name=response.name).state\n",
    "    print(job_state)\n",
    "    if job_state not in (\n",
    "        aiplatform_v1.JobState.JOB_STATE_QUEUED,\n",
    "        aiplatform_v1.JobState.JOB_STATE_PENDING,\n",
    "        aiplatform_v1.JobState.JOB_STATE_RUNNING\n",
    "    ):\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure we can actually predict with savedmodel (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-21T06:06:58Z  gs://dsparing-sandbox-bucket/jax/output/model/\n",
      "     44207  2021-06-26T08:09:13Z  gs://dsparing-sandbox-bucket/jax/output/model/saved_model.pb\n",
      "                                 gs://dsparing-sandbox-bucket/jax/output/model/assets/\n",
      "                                 gs://dsparing-sandbox-bucket/jax/output/model/variables/\n",
      "TOTAL: 2 objects, 44207 bytes (43.17 KiB)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls -l gs://$BUCKET_NAME/jax/output/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/jupyter/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split test, from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "# need to initialize flags somehow to avoid errors in load_mnist\n",
    "flags.FLAGS(['e'])\n",
    "\n",
    "image_to_predict, _ = next(iter(load_mnist(tfds.Split.TEST, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[ -2.8519683, -22.318636 ,  -6.8104887, -13.863109 ,  -0.7156592,\n",
       "          -3.3984666,  -1.8780065,  -7.833604 ,  -1.581222 ,  -2.815784 ]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(f\"gs://{BUCKET_NAME}/jax/output/model\")\n",
    "loaded_model.signatures[\"serving_default\"](image_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "JAX Flax MNIST containerize",
   "provenance": [
    {
     "file_id": "1HenHxSnSqNQPqMPZNG_uhFampEPxN_Cj",
     "timestamp": 1617196427779
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
