{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train JAX/Flax model on Vertex AI pre-built container and use `jax2tf` to convert to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v-kebtVqdEyV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import flags\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from jax.experimental.jax2tf.examples.mnist_lib import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W-IAEp1UqmKR",
    "tags": [
     "flake8-noqa-line-1"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "BUCKET_NAME = PROJECT_ID\n",
    "os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "os.environ['TRAINING_APP_FOLDER'] = TRAINING_APP_FOLDER\n",
    "\n",
    "MODEL_NAME = \"jax_model_prebuilt\"\n",
    "MODELPACKAGE_DIR = f\"gs://{BUCKET_NAME}/models/{MODEL_NAME}/package\"\n",
    "MODELPACKAGE_NAME = \"jax_flax_trainer-0.1.tar.gz\"\n",
    "SAVEDMODEL_BASEDIR = f\"gs://{BUCKET_NAME}/models/{MODEL_NAME}/output\"\n",
    "os.environ['MODELPACKAGE_DIR'] = MODELPACKAGE_DIR\n",
    "os.environ['MODELPACKAGE_NAME'] = MODELPACKAGE_NAME\n",
    "os.environ['SAVEDMODEL_BASEDIR'] = SAVEDMODEL_BASEDIR\n",
    "\n",
    "# Block TF from the GPU to let JAX use it all\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no pre-built Vertex TF2.5 container yet, and `jax.experimental.jax2tf.examples.saved_model_lib.convert_and_save_model` uses the `jit_compile` argument for `tf.function`, which is the TF2.5 new name for `experimental_compile`. So we define a copy `./saved_model_lib_tf24.py` of that module with the only difference that jit_compile is still called `experimental_compile` for TF2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no pre-built Vertex TF2.5 container yet, and jax2tf in jax==0.2.14 uses `tensorflow.compiler.tf2xla.conv(... preferred_element_type)` which is not there in TF2.4, only in TF2.5. We can avoid this though by using `convert_and_save_model( ... enable_xla=False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "import argparse\n",
      "import logging\n",
      "import os\n",
      "\n",
      "import tensorflow as tf\n",
      "import tensorflow_datasets as tfds\n",
      "from absl import flags\n",
      "from jax.experimental.jax2tf.examples.mnist_lib import (\n",
      "    load_mnist, FlaxMNIST\n",
      ")\n",
      "# from jax.experimental.jax2tf.examples.saved_model_lib import (\n",
      "#     convert_and_save_model\n",
      "# )\n",
      "\n",
      "from trainer.saved_model_lib_tf2_4 import convert_and_save_model\n",
      "\n",
      "TRAIN_BATCH_SIZE = 128\n",
      "TEST_BATCH_SIZE = 16\n",
      "NUM_EPOCHS = 2\n",
      "\n",
      "# Block TF from the GPU to let JAX use it all\n",
      "tf.config.set_visible_devices([], 'GPU')\n",
      "\n",
      "logger = logging.getLogger()\n",
      "\n",
      "# need to initialize flags somehow to avoid errors in load_mnist\n",
      "flags.FLAGS(['e'])\n",
      "\n",
      "flax_mnist = FlaxMNIST()\n",
      "\n",
      "train_ds = load_mnist(tfds.Split.TRAIN, TRAIN_BATCH_SIZE)\n",
      "test_ds = load_mnist(tfds.Split.TEST, TEST_BATCH_SIZE)\n",
      "\n",
      "image, _ = next(iter(train_ds))\n",
      "input_signature = tf.TensorSpec.from_tensor(\n",
      "    tf.expand_dims(image[0], axis=0)\n",
      ")\n",
      "\n",
      "\n",
      "def main(output_dir):\n",
      "    logger.setLevel(logging.INFO)\n",
      "    predict_fn, params = flax_mnist.train(\n",
      "        train_ds=train_ds,\n",
      "        test_ds=test_ds,\n",
      "        num_epochs=NUM_EPOCHS,\n",
      "    )\n",
      "    logger.setLevel(logging.NOTSET)\n",
      "\n",
      "    convert_and_save_model(\n",
      "        jax_fn=predict_fn,\n",
      "        params=params,\n",
      "        model_dir=output_dir,\n",
      "        input_signatures=[input_signature],\n",
      "        enable_xla=False,\n",
      "    )\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\n",
      "        \"--output_dir\",\n",
      "        help=\"GCS location to export SavedModel\",\n",
      "        default=os.getenv(\"AIP_MODEL_DIR\")\n",
      "    )\n",
      "    args = parser.parse_args().__dict__\n",
      "\n",
      "    main(output_dir=args[\"output_dir\"])\n"
     ]
    }
   ],
   "source": [
    "!cat $TRAINING_APP_FOLDER/trainer/task_tf2_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training Python package locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-27 06:47:03.972535: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-06-27 06:47:03.972740: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "INFO:absl:Starting the local TPU driver.\n",
      "INFO:absl:Unable to initialize backend 'tpu_driver': Not found: Unable to find driver in registry given worker: local://\n",
      "INFO:absl:Unable to initialize backend 'tpu': Invalid argument: TpuPlatform is not available.\n",
      "INFO:root:mnist_flax: Epoch 0 in 6.06 sec\n",
      "INFO:root:mnist_flax: Training set accuracy 88.41%\n",
      "INFO:root:mnist_flax: Test set accuracy 88.93%\n",
      "INFO:root:mnist_flax: Epoch 1 in 1.08 sec\n",
      "INFO:root:mnist_flax: Training set accuracy 90.99%\n",
      "INFO:root:mnist_flax: Test set accuracy 91.48%\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function convert_and_save_model.<locals>.<lambda> at 0x7f41b01a95f0> (key: CacheKey(input_signature=('URu', (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name=None),)), parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function convert_and_save_model.<locals>.<lambda> at 0x7f41b01a95f0> (key: CacheKey(input_signature=('URu', (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name=None),)), parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name=None),)] [kwargs: {}]\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name=None),)] [kwargs: {}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f41b0074ef0> (key: CacheKey(input_signature=('UUuDRRu', ('inputs', TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs'))), parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f41b0074ef0> (key: CacheKey(input_signature=('UUuDRRu', ('inputs', TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs'))), parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 2:tensorflow:Python function signature [args: ()] [kwargs: {'inputs': TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs')}]\n",
      "Level 2:tensorflow:Python function signature [args: ()] [kwargs: {'inputs': TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs')}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function convert_and_save_model.<locals>.<lambda> at 0x7f41b01a95f0> (key: CacheKey(input_signature=('URu', (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs'),)), parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function convert_and_save_model.<locals>.<lambda> at 0x7f41b01a95f0> (key: CacheKey(input_signature=('URu', (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs'),)), parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs'),)] [kwargs: {}]\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(1, 28, 28, 1), dtype=tf.float32, name='inputs'),)] [kwargs: {}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function MultiDeviceSaver._traced_save at 0x7f41884ca8c0> (key: CacheKey(input_signature=(TensorSpec(shape=(), dtype=tf.string, name=None),), parent_graph=<tensorflow.python.framework.ops.Graph object at 0x7f41b0a64d10>, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function MultiDeviceSaver._traced_save at 0x7f41884ca8c0> (key: CacheKey(input_signature=(TensorSpec(shape=(), dtype=tf.string, name=None),), parent_graph=<tensorflow.python.framework.ops.Graph object at 0x7f41b0a64d10>, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 2:tensorflow:Python function signature [args: None] [kwargs: None]\n",
      "Level 2:tensorflow:Python function signature [args: None] [kwargs: None]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function MultiDeviceSaver._traced_restore at 0x7f41884714d0> (key: CacheKey(input_signature=(TensorSpec(shape=(), dtype=tf.string, name=None),), parent_graph=<tensorflow.python.framework.ops.Graph object at 0x7f41b0a64d10>, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function MultiDeviceSaver._traced_restore at 0x7f41884714d0> (key: CacheKey(input_signature=(TensorSpec(shape=(), dtype=tf.string, name=None),), parent_graph=<tensorflow.python.framework.ops.Graph object at 0x7f41b0a64d10>, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=<VariablePolicy.NONE: None>, xla_context_id=0))\n",
      "Level 2:tensorflow:Python function signature [args: None] [kwargs: None]\n",
      "Level 2:tensorflow:Python function signature [args: None] [kwargs: None]\n",
      "INFO:tensorflow:Assets written to: gs://dsparing-sandbox/models/jax_model_prebuilt/output/localmodel/assets\n",
      "INFO:tensorflow:Assets written to: gs://dsparing-sandbox/models/jax_model_prebuilt/output/localmodel/assets\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=${PYTHONPATH}:${PWD}/$TRAINING_APP_FOLDER && \\\n",
    "    python3 -m trainer.task_tf2_4 --output_dir=$SAVEDMODEL_BASEDIR/localmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to use [CustomTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob) (which would read a local Python package) or [CustomPythonPackageTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomPythonPackageTrainingJob) from the high-level API, which would not just train the model on Vertex AI, but would also upload it as a Vertex AI model; however, as we need to pass `jaxlib` as a second Python package (and the high-level API expects only one), we use [create_custom_job](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1/job_service.html?#google.cloud.aiplatform_v1.services.job_service.JobServiceClient.create_custom_job) from the low-level API. For this, first we need to create a source distribution and upload it to Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a source distribution and upload to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "from setuptools import find_packages\n",
      "from setuptools import setup\n",
      "\n",
      "REQUIRED_PACKAGES = ['flax', 'jax']\n",
      "\n",
      "setup(\n",
      "    name='jax_flax_trainer',\n",
      "    version='0.1',\n",
      "    install_requires=REQUIRED_PACKAGES,\n",
      "    packages=find_packages(),\n",
      "    include_package_data=True,\n",
      "    description='JAX/FLAX model training application.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!cat $TRAINING_APP_FOLDER/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing jax_flax_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to jax_flax_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to jax_flax_trainer.egg-info/requires.txt\n",
      "writing top-level names to jax_flax_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating jax_flax_trainer-0.1\n",
      "creating jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "creating jax_flax_trainer-0.1/trainer\n",
      "copying files to jax_flax_trainer-0.1...\n",
      "copying setup.py -> jax_flax_trainer-0.1\n",
      "copying jax_flax_trainer.egg-info/PKG-INFO -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/SOURCES.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/dependency_links.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/requires.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/top_level.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying trainer/__init__.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/saved_model_lib_tf2_4.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task_tf2_4.py -> jax_flax_trainer-0.1/trainer\n",
      "Writing jax_flax_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'jax_flax_trainer-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!cd $TRAINING_APP_FOLDER && python ./setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!gsutil -q cp $TRAINING_APP_FOLDER/dist/$MODELPACKAGE_NAME $MODELPACKAGE_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run custom training job with Python package on Vertex AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAXLIB_URI = (\"gs://jax-releases/cuda110/jaxlib-0.1.67+\"\n",
    "              \"cuda110-cp37-none-manylinux2010_x86_64.whl\")\n",
    "PYTHON_PACKAGE_URIS = [f\"{MODELPACKAGE_DIR}/{MODELPACKAGE_NAME}\", JAXLIB_URI]\n",
    "PYTHON_MODULE = \"trainer.task_tf2_4\"\n",
    "\n",
    "if USE_GPU:\n",
    "    TRAINING_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "else:\n",
    "    TRAINING_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-4:latest'\n",
    "    \n",
    "python_package_spec = {\n",
    "    \"executor_image_uri\": TRAINING_IMAGE,\n",
    "    \"package_uris\": PYTHON_PACKAGE_URIS,\n",
    "    \"python_module\": PYTHON_MODULE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex AI machines to use for training\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "REPLICA_COUNT = 1\n",
    "\n",
    "if USE_GPU:\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "else:\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None\n",
    "\n",
    "worker_pool_spec = {\n",
    "    \"machine_spec\": {\n",
    "        \"machine_type\": MACHINE_TYPE,\n",
    "        \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "        \"accelerator_count\": ACCELERATOR_COUNT,\n",
    "    },\n",
    "    \"replica_count\": REPLICA_COUNT,\n",
    "    \"python_package_spec\": python_package_spec,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = \"jax_prebuilt_training\"\n",
    "\n",
    "custom_job = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": {\n",
    "        \"worker_pool_specs\": [worker_pool_spec],\n",
    "        \"base_output_directory\": {\n",
    "            \"output_uri_prefix\": SAVEDMODEL_BASEDIR\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_endpoint: str = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: name: \"projects/654544512569/locations/us-central1/customJobs/5056579209351135232\"\n",
      "display_name: \"jax_prebuilt_training\"\n",
      "job_spec {\n",
      "  worker_pool_specs {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "      accelerator_type: NVIDIA_TESLA_T4\n",
      "      accelerator_count: 1\n",
      "    }\n",
      "    replica_count: 1\n",
      "    disk_spec {\n",
      "      boot_disk_type: \"pd-ssd\"\n",
      "      boot_disk_size_gb: 100\n",
      "    }\n",
      "    python_package_spec {\n",
      "      executor_image_uri: \"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest\"\n",
      "      package_uris: \"gs://dsparing-sandbox/models/jax_model_prebuilt/package/jax_flax_trainer-0.1.tar.gz\"\n",
      "      package_uris: \"gs://jax-releases/cuda110/jaxlib-0.1.67+cuda110-cp37-none-manylinux2010_x86_64.whl\"\n",
      "      python_module: \"trainer.task_tf2_4\"\n",
      "    }\n",
      "  }\n",
      "  base_output_directory {\n",
      "    output_uri_prefix: \"gs://dsparing-sandbox/models/jax_model_prebuilt/output\"\n",
      "  }\n",
      "}\n",
      "state: JOB_STATE_PENDING\n",
      "create_time {\n",
      "  seconds: 1624776457\n",
      "  nanos: 306704000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1624776457\n",
      "  nanos: 306704000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.create_custom_job(parent=parent, custom_job=custom_job)\n",
    "print(\"response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_state = client.get_custom_job(name=response.name).state\n",
    "    print(job_state)\n",
    "    if job_state not in (\n",
    "        aiplatform_v1.JobState.JOB_STATE_QUEUED,\n",
    "        aiplatform_v1.JobState.JOB_STATE_PENDING,\n",
    "        aiplatform_v1.JobState.JOB_STATE_RUNNING\n",
    "    ):\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local prediction with SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-27T06:32:36Z  gs://dsparing-sandbox/models/jax_model_prebuilt/output/model/\n",
      "     44195  2021-06-27T06:51:17Z  gs://dsparing-sandbox/models/jax_model_prebuilt/output/model/saved_model.pb\n",
      "                                 gs://dsparing-sandbox/models/jax_model_prebuilt/output/model/assets/\n",
      "                                 gs://dsparing-sandbox/models/jax_model_prebuilt/output/model/variables/\n",
      "TOTAL: 2 objects, 44195 bytes (43.16 KiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l $SAVEDMODEL_BASEDIR/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/jupyter/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split test, from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "# need to initialize flags somehow to avoid errors in load_mnist\n",
    "flags.FLAGS(['e'])\n",
    "\n",
    "image_to_predict, _ = next(iter(load_mnist(tfds.Split.TEST, batch_size=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[-6.8632755, -4.290162 , -2.6556697, -2.2902765, -2.8904533,\n",
       "         -2.83985  , -5.353467 , -4.57983  , -0.7665547, -1.5133249]],\n",
       "       dtype=float32)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(f\"{SAVEDMODEL_BASEDIR}/model\")\n",
    "loaded_model.signatures[\"serving_default\"](image_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "JAX Flax MNIST containerize",
   "provenance": [
    {
     "file_id": "1HenHxSnSqNQPqMPZNG_uhFampEPxN_Cj",
     "timestamp": 1617196427779
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
