{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train JAX/Flax model on Vertex AI pre-built container and use `jax2tf` to convert to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v-kebtVqdEyV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import flags\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from jax.experimental.jax2tf.examples import mnist_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W-IAEp1UqmKR",
    "tags": [
     "flake8-noqa-line-1"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "BUCKET_NAME = PROJECT_ID\n",
    "os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "os.environ['TRAINING_APP_FOLDER'] = TRAINING_APP_FOLDER\n",
    "\n",
    "MODEL_NAME = \"jax_model_prebuilt\"\n",
    "\n",
    "MODELPACKAGE_DIR = f\"gs://{BUCKET_NAME}/trainers/{MODEL_NAME}\"\n",
    "MODELPACKAGE_NAME = \"jax_flax_trainer-0.1.tar.gz\"\n",
    "\n",
    "MODEL_BASE_PATH = f\"gs://{BUCKET_NAME}/savedmodels\"\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['MODELPACKAGE_DIR'] = MODELPACKAGE_DIR\n",
    "os.environ['MODELPACKAGE_NAME'] = MODELPACKAGE_NAME\n",
    "os.environ['MODEL_BASE_PATH'] = MODEL_BASE_PATH\n",
    "os.environ['MODEL_VERSION'] = str(MODEL_VERSION)\n",
    "\n",
    "# Block TF from the GPU to let JAX use it all\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no pre-built Vertex TF2.5 container yet, and\n",
    "- `jax.experimental.jax2tf.examples.saved_model_lib.convert_and_save_model` uses the `jit_compile` argument for `tf.function`, which is the TF2.5 new name for `experimental_compile`. So we define a copy `./saved_model_lib_tf24.py` of that module with the only difference that jit_compile is still called `experimental_compile` for TF2.4.\n",
    "- jax2tf in jax==0.2.14 uses `tensorflow.compiler.tf2xla.conv(... preferred_element_type)` which is not there in TF2.4, only in TF2.5. We can avoid this though by using `convert_and_save_model( ... enable_xla=False)`.\n",
    "\n",
    "To work around the above limitations, we'll use the the slightly modified `task_tf2_4.py` version of `task.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "import argparse\n",
      "import logging\n",
      "import os\n",
      "\n",
      "import tensorflow as tf\n",
      "import tensorflow_datasets as tfds\n",
      "from absl import flags\n",
      "from jax.experimental.jax2tf.examples import mnist_lib\n",
      "\n",
      "from trainer import saved_model_lib_tf2_4\n",
      "\n",
      "TRAIN_BATCH_SIZE = 128\n",
      "TEST_BATCH_SIZE = 16\n",
      "NUM_EPOCHS = 2\n",
      "\n",
      "# Block TF from the GPU to let JAX use it all\n",
      "tf.config.set_visible_devices([], 'GPU')\n",
      "\n",
      "logger = logging.getLogger()\n",
      "\n",
      "# need to initialize flags somehow to avoid errors in load_mnist\n",
      "flags.FLAGS([''])\n",
      "\n",
      "flax_mnist = mnist_lib.FlaxMNIST()\n",
      "\n",
      "train_ds = mnist_lib.load_mnist(tfds.Split.TRAIN, TRAIN_BATCH_SIZE)\n",
      "test_ds = mnist_lib.load_mnist(tfds.Split.TEST, TEST_BATCH_SIZE)\n",
      "\n",
      "image, _ = next(iter(train_ds))\n",
      "input_signature = tf.TensorSpec.from_tensor(\n",
      "    tf.expand_dims(image[0], axis=0)\n",
      ")\n",
      "\n",
      "\n",
      "def main(args):\n",
      "    logger_level = logger.level\n",
      "    logger.setLevel(logging.INFO)\n",
      "    predict_fn, params = flax_mnist.train(\n",
      "        train_ds=train_ds,\n",
      "        test_ds=test_ds,\n",
      "        num_epochs=NUM_EPOCHS,\n",
      "    )\n",
      "    logger.setLevel(logger_level)\n",
      "\n",
      "    saved_model_lib_tf2_4.convert_and_save_model(\n",
      "        jax_fn=predict_fn,\n",
      "        params=params,\n",
      "        model_dir=os.path.join(\n",
      "            args[\"output_dir\"],\n",
      "            \"model\",\n",
      "            str(args[\"model_version\"])\n",
      "        ),\n",
      "        input_signatures=[input_signature],\n",
      "        enable_xla=False,\n",
      "    )\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\n",
      "        \"--output_dir\",\n",
      "        help=\"GCS location to export model_version/SavedModel\",\n",
      "        default=os.getenv(\"AIP_MODEL_DIR\")\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--model_version\",\n",
      "        default=1,\n",
      "        type=int\n",
      "    )\n",
      "\n",
      "    args = parser.parse_args().__dict__\n",
      "\n",
      "    main(args=args)\n"
     ]
    }
   ],
   "source": [
    "!cat $TRAINING_APP_FOLDER/trainer/task_tf2_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training Python package locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 05:15:32.486451: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2021-06-29 05:15:32.486811: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "INFO:absl:Starting the local TPU driver.\n",
      "INFO:absl:Unable to initialize backend 'tpu_driver': Not found: Unable to find driver in registry given worker: local://\n",
      "INFO:absl:Unable to initialize backend 'tpu': Invalid argument: TpuPlatform is not available.\n",
      "INFO:root:mnist_flax: Epoch 0 in 5.33 sec\n",
      "INFO:root:mnist_flax: Training set accuracy 88.51%\n",
      "INFO:root:mnist_flax: Test set accuracy 89.08%\n",
      "INFO:root:mnist_flax: Epoch 1 in 1.10 sec\n",
      "INFO:root:mnist_flax: Training set accuracy 90.62%\n",
      "INFO:root:mnist_flax: Test set accuracy 91.16%\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=${PYTHONPATH}:${PWD}/$TRAINING_APP_FOLDER && \\\n",
    "    python3 -m trainer.task_tf2_4 \\\n",
    "        --output_dir=$MODEL_BASE_PATH/${MODEL_NAME}_local \\\n",
    "        --model_version=$MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-29T05:15:53Z  gs://dsparing-sandbox/savedmodels/jax_model_prebuilt_local/model/1/\n",
      "     44744  2021-06-29T05:15:58Z  gs://dsparing-sandbox/savedmodels/jax_model_prebuilt_local/model/1/saved_model.pb\n",
      "                                 gs://dsparing-sandbox/savedmodels/jax_model_prebuilt_local/model/1/assets/\n",
      "                                 gs://dsparing-sandbox/savedmodels/jax_model_prebuilt_local/model/1/variables/\n",
      "TOTAL: 2 objects, 44744 bytes (43.7 KiB)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls -l $MODEL_BASE_PATH/${MODEL_NAME}_local/model/$MODEL_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to use [CustomTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob) (which would read a local Python package) or [CustomPythonPackageTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomPythonPackageTrainingJob) from the high-level API, which would not just train the model on Vertex AI, but would also upload it as a Vertex AI model; however, as we need to pass `jaxlib` as a second Python package (and the high-level API expects only one), we use [create_custom_job](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1/job_service.html?#google.cloud.aiplatform_v1.services.job_service.JobServiceClient.create_custom_job) from the low-level API. For this, first we need to create a source distribution and upload it to Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a source distribution and upload to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "from setuptools import find_packages\n",
      "from setuptools import setup\n",
      "\n",
      "REQUIRED_PACKAGES = ['flax', 'jax']\n",
      "\n",
      "setup(\n",
      "    name='jax_flax_trainer',\n",
      "    version='0.1',\n",
      "    install_requires=REQUIRED_PACKAGES,\n",
      "    packages=find_packages(),\n",
      "    include_package_data=True,\n",
      "    description='JAX/FLAX model training application.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!cat $TRAINING_APP_FOLDER/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing jax_flax_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to jax_flax_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to jax_flax_trainer.egg-info/requires.txt\n",
      "writing top-level names to jax_flax_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating jax_flax_trainer-0.1\n",
      "creating jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "creating jax_flax_trainer-0.1/trainer\n",
      "copying files to jax_flax_trainer-0.1...\n",
      "copying setup.py -> jax_flax_trainer-0.1\n",
      "copying jax_flax_trainer.egg-info/PKG-INFO -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/SOURCES.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/dependency_links.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/requires.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/top_level.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying trainer/__init__.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/saved_model_lib_tf2_4.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task_tf2_4.py -> jax_flax_trainer-0.1/trainer\n",
      "Writing jax_flax_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'jax_flax_trainer-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!cd $TRAINING_APP_FOLDER && python ./setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!gsutil -q cp $TRAINING_APP_FOLDER/dist/$MODELPACKAGE_NAME $MODELPACKAGE_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run custom training job with Python package on Vertex AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAXLIB_URI = (\"gs://jax-releases/cuda110/jaxlib-0.1.67+\"\n",
    "              \"cuda110-cp37-none-manylinux2010_x86_64.whl\")\n",
    "PYTHON_PACKAGE_URIS = [f\"{MODELPACKAGE_DIR}/{MODELPACKAGE_NAME}\", JAXLIB_URI]\n",
    "PYTHON_MODULE = \"trainer.task_tf2_4\"\n",
    "\n",
    "if USE_GPU:\n",
    "    TRAINING_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "else:\n",
    "    TRAINING_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-4:latest'\n",
    "\n",
    "python_package_spec = {\n",
    "    \"executor_image_uri\": TRAINING_IMAGE,\n",
    "    \"package_uris\": PYTHON_PACKAGE_URIS,\n",
    "    \"python_module\": PYTHON_MODULE,\n",
    "    \"args\": [\n",
    "         f\"--model_version={MODEL_VERSION}\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex AI machines to use for training\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "REPLICA_COUNT = 1\n",
    "\n",
    "if USE_GPU:\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "else:\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None\n",
    "\n",
    "worker_pool_spec = {\n",
    "    \"machine_spec\": {\n",
    "        \"machine_type\": MACHINE_TYPE,\n",
    "        \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "        \"accelerator_count\": ACCELERATOR_COUNT,\n",
    "    },\n",
    "    \"replica_count\": REPLICA_COUNT,\n",
    "    \"python_package_spec\": python_package_spec,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = \"jax_prebuilt_training\"\n",
    "\n",
    "custom_job = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": {\n",
    "        \"worker_pool_specs\": [worker_pool_spec],\n",
    "        \"base_output_directory\": {\n",
    "            \"output_uri_prefix\": os.path.join(MODEL_BASE_PATH, MODEL_NAME),\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_endpoint: str = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: name: \"projects/654544512569/locations/us-central1/customJobs/1972457889532477440\"\n",
      "display_name: \"jax_prebuilt_training\"\n",
      "job_spec {\n",
      "  worker_pool_specs {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "      accelerator_type: NVIDIA_TESLA_T4\n",
      "      accelerator_count: 1\n",
      "    }\n",
      "    replica_count: 1\n",
      "    disk_spec {\n",
      "      boot_disk_type: \"pd-ssd\"\n",
      "      boot_disk_size_gb: 100\n",
      "    }\n",
      "    python_package_spec {\n",
      "      executor_image_uri: \"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest\"\n",
      "      package_uris: \"gs://dsparing-sandbox/trainers/jax_model_prebuilt/jax_flax_trainer-0.1.tar.gz\"\n",
      "      package_uris: \"gs://jax-releases/cuda110/jaxlib-0.1.67+cuda110-cp37-none-manylinux2010_x86_64.whl\"\n",
      "      python_module: \"trainer.task_tf2_4\"\n",
      "      args: \"--model_version=1\"\n",
      "    }\n",
      "  }\n",
      "  base_output_directory {\n",
      "    output_uri_prefix: \"gs://dsparing-sandbox/savedmodels/jax_model_prebuilt\"\n",
      "  }\n",
      "}\n",
      "state: JOB_STATE_PENDING\n",
      "create_time {\n",
      "  seconds: 1624943763\n",
      "  nanos: 669955000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1624943763\n",
      "  nanos: 669955000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.create_custom_job(parent=parent, custom_job=custom_job)\n",
    "print(\"response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_state = client.get_custom_job(name=response.name).state\n",
    "    print(job_state)\n",
    "    if job_state not in (\n",
    "        aiplatform_v1.JobState.JOB_STATE_QUEUED,\n",
    "        aiplatform_v1.JobState.JOB_STATE_PENDING,\n",
    "        aiplatform_v1.JobState.JOB_STATE_RUNNING\n",
    "    ):\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local prediction with SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the timestamps below that the model is newly written:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thre first 'model' comes from Vertex AI using [AIP_MODEL_DIR == baseOutputDirectory/model/](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec#FIELDS.base_output_directory), and the second 'model' is hard-coded in task.py. (TODO: probably could be made a parameter, if otherwise it end-to-end works.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-29T05:30:02Z  gs://dsparing-sandbox/savedmodels/jax_model_prebuilt/model/model/1/\n",
      "     44195  2021-06-29T05:30:05Z  gs://dsparing-sandbox/savedmodels/jax_model_prebuilt/model/model/1/saved_model.pb\n",
      "                                 gs://dsparing-sandbox/savedmodels/jax_model_prebuilt/model/model/1/assets/\n",
      "                                 gs://dsparing-sandbox/savedmodels/jax_model_prebuilt/model/model/1/variables/\n",
      "TOTAL: 2 objects, 44195 bytes (43.16 KiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l $MODEL_BASE_PATH/$MODEL_NAME/model/model/$MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/jupyter/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split test, from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "# need to initialize flags somehow to avoid errors in load_mnist\n",
    "flags.FLAGS([''])\n",
    "\n",
    "image_to_predict, _ = next(iter(\n",
    "    mnist_lib.load_mnist(tfds.Split.TEST, batch_size=1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       " array([[ -9.584547  , -14.949548  , -14.130246  ,  -7.6144347 ,\n",
       "          -6.267856  ,  -6.8413506 , -15.46014   ,  -0.18444702,\n",
       "          -7.8782682 ,  -1.8046691 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(os.path.join(\n",
    "    MODEL_BASE_PATH, MODEL_NAME, 'model', 'model', str(MODEL_VERSION))\n",
    ")\n",
    "loaded_model.signatures[\"serving_default\"](image_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "JAX Flax MNIST containerize",
   "provenance": [
    {
     "file_id": "1HenHxSnSqNQPqMPZNG_uhFampEPxN_Cj",
     "timestamp": 1617196427779
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
