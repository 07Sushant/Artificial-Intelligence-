{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train JAX/Flax model on Vertex AI pre-built container and use `jax2tf` to convert to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v-kebtVqdEyV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import flags\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "from jax.experimental.jax2tf.examples import mnist_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W-IAEp1UqmKR",
    "tags": [
     "flake8-noqa-line-1"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "BUCKET_NAME = PROJECT_ID\n",
    "# Use a regional bucket in the above region you have rights to.\n",
    "# Create if needed:\n",
    "# !gsutil mb -l $REGION gs://$BUCKET_NAME\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "TRAINING_APP_FOLDER = 'training_app'\n",
    "\n",
    "MODEL_NAME = \"jax_model_prebuilt\"\n",
    "\n",
    "MODELPACKAGE_DIR = f\"gs://{BUCKET_NAME}/trainers/{MODEL_NAME}\"\n",
    "MODELPACKAGE_NAME = \"jax_flax_trainer-0.1.tar.gz\"\n",
    "\n",
    "BASE_OUTPUT_DIR = f\"gs://{BUCKET_NAME}\"\n",
    "MODEL_VERSION = 1\n",
    "\n",
    "SERVING_BATCH_SIZE = 3\n",
    "\n",
    "# Block TF from the GPU to let JAX use it all\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no pre-built Vertex TF2.5 container yet, and\n",
    "- `jax.experimental.jax2tf.examples.saved_model_lib.convert_and_save_model` uses the `jit_compile` argument for `tf.function`, which is the TF2.5 new name for `experimental_compile`. So we define a copy `./saved_model_lib_tf24.py` of that module with the only difference that jit_compile is still called `experimental_compile` for TF2.4.\n",
    "- jax2tf in jax==0.2.14 uses `tensorflow.compiler.tf2xla.conv(... preferred_element_type)` which is not there in TF2.4, only in TF2.5. We can avoid this though by using `convert_and_save_model( ... enable_xla=False)`.\n",
    "\n",
    "To work around the above limitations, we'll use the the slightly modified `task_tf2_4.py` version of `task.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "import argparse\n",
      "import logging\n",
      "import os\n",
      "\n",
      "import tensorflow as tf\n",
      "import tensorflow_datasets as tfds\n",
      "from absl import flags\n",
      "from jax.experimental.jax2tf.examples import mnist_lib\n",
      "\n",
      "from trainer import saved_model_lib_tf2_4\n",
      "\n",
      "TRAIN_BATCH_SIZE = 128\n",
      "TEST_BATCH_SIZE = 16\n",
      "NUM_EPOCHS = 2\n",
      "\n",
      "# Block TF from the GPU to let JAX use it all\n",
      "tf.config.set_visible_devices([], \"GPU\")\n",
      "\n",
      "logger = logging.getLogger()\n",
      "\n",
      "# need to initialize flags somehow to avoid errors in load_mnist\n",
      "flags.FLAGS([\"\"])\n",
      "\n",
      "flax_mnist = mnist_lib.FlaxMNIST()\n",
      "\n",
      "train_ds = mnist_lib.load_mnist(tfds.Split.TRAIN, TRAIN_BATCH_SIZE)\n",
      "test_ds = mnist_lib.load_mnist(tfds.Split.TEST, TEST_BATCH_SIZE)\n",
      "\n",
      "# Batch-polymorphic SavedModel\n",
      "input_signatures = [tf.TensorSpec((None,) + mnist_lib.input_shape, tf.float32),]\n",
      "polymorphic_shapes = \"(batch, ...)\"\n",
      "\n",
      "\n",
      "def main(args):\n",
      "    logger_level = logger.level\n",
      "    logger.setLevel(logging.INFO)\n",
      "    predict_fn, params = flax_mnist.train(\n",
      "        train_ds=train_ds,\n",
      "        test_ds=test_ds,\n",
      "        num_epochs=NUM_EPOCHS,\n",
      "    )\n",
      "    logger.setLevel(logger_level)\n",
      "\n",
      "    saved_model_lib_tf2_4.convert_and_save_model(\n",
      "        jax_fn=predict_fn,\n",
      "        params=params,\n",
      "        model_dir=os.path.join(\n",
      "            args[\"output_dir\"], args[\"model_name\"], str(args[\"model_version\"])\n",
      "        ),\n",
      "        input_signatures=input_signatures,\n",
      "        polymorphic_shapes=polymorphic_shapes,\n",
      "        enable_xla=False,\n",
      "    )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\n",
      "        \"--output_dir\",\n",
      "        help=\"GCS location to export model_version/SavedModel\",\n",
      "        default=os.getenv(\"AIP_MODEL_DIR\"),\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--model_name\",\n",
      "        default=\"model\",\n",
      "    )\n",
      "    parser.add_argument(\"--model_version\", default=1, type=int)\n",
      "\n",
      "    args = parser.parse_args().__dict__\n",
      "\n",
      "    main(args=args)\n"
     ]
    }
   ],
   "source": [
    "!cat $TRAINING_APP_FOLDER/trainer/task_tf2_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training Python package locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Starting the local TPU driver.\n",
      "INFO:absl:Unable to initialize backend 'tpu_driver': Not found: Unable to find driver in registry given worker: local://\n",
      "INFO:absl:Unable to initialize backend 'tpu': Invalid argument: TpuPlatform is not available.\n",
      "INFO:root:mnist_flax: Epoch 0 in 5.81 sec\n",
      "INFO:root:mnist_flax: Training set accuracy 88.60%\n",
      "INFO:root:mnist_flax: Test set accuracy 89.03%\n",
      "INFO:root:mnist_flax: Epoch 1 in 1.11 sec\n",
      "INFO:root:mnist_flax: Training set accuracy 90.70%\n",
      "INFO:root:mnist_flax: Test set accuracy 91.05%\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'flax.core.frozen_dict.FrozenDict'>\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TRAINING_APP_FOLDER\"] = TRAINING_APP_FOLDER\n",
    "os.environ[\"BASE_OUTPUT_DIR\"] = BASE_OUTPUT_DIR\n",
    "os.environ[\"MODEL_NAME\"] = MODEL_NAME\n",
    "os.environ[\"MODEL_VERSION\"] = str(MODEL_VERSION)\n",
    "\n",
    "!export PYTHONPATH=${PYTHONPATH}:${PWD}/$TRAINING_APP_FOLDER && \\\n",
    "    python3 -m trainer.task_tf2_4 \\\n",
    "        --output_dir=$BASE_OUTPUT_DIR/model \\\n",
    "        --model_name=\"$MODEL_NAME\"_local \\\n",
    "        --model_version=$MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-29T23:39:16Z  gs://dsparing-sandbox/model/jax_model_prebuilt_local/1/\n",
      "     50304  2021-07-01T14:34:20Z  gs://dsparing-sandbox/model/jax_model_prebuilt_local/1/saved_model.pb\n",
      "                                 gs://dsparing-sandbox/model/jax_model_prebuilt_local/1/assets/\n",
      "                                 gs://dsparing-sandbox/model/jax_model_prebuilt_local/1/variables/\n",
      "TOTAL: 2 objects, 50304 bytes (49.12 KiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l $BASE_OUTPUT_DIR/model/\"$MODEL_NAME\"_local/$MODEL_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should be able to use [CustomTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomTrainingJob) (which would read a local Python package) or [CustomPythonPackageTrainingJob](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.CustomPythonPackageTrainingJob) from the high-level API, which would not just train the model on Vertex AI, but would also upload it as a Vertex AI model; however, as we need to pass `jaxlib` as a second Python package (and the high-level API expects only one), we use [create_custom_job](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1/job_service.html?#google.cloud.aiplatform_v1.services.job_service.JobServiceClient.create_custom_job) from the low-level API. For this, first we need to create a source distribution and upload it to Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a source distribution and upload to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2021 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "from setuptools import find_packages, setup\n",
      "\n",
      "REQUIRED_PACKAGES = [\"flax\", \"jax\"]\n",
      "\n",
      "setup(\n",
      "    name=\"jax_flax_trainer\",\n",
      "    version=\"0.1\",\n",
      "    install_requires=REQUIRED_PACKAGES,\n",
      "    packages=find_packages(),\n",
      "    include_package_data=True,\n",
      "    description=\"JAX/FLAX model training application.\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!cat $TRAINING_APP_FOLDER/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing jax_flax_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to jax_flax_trainer.egg-info/dependency_links.txt\n",
      "writing requirements to jax_flax_trainer.egg-info/requires.txt\n",
      "writing top-level names to jax_flax_trainer.egg-info/top_level.txt\n",
      "reading manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'jax_flax_trainer.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating jax_flax_trainer-0.1\n",
      "creating jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "creating jax_flax_trainer-0.1/trainer\n",
      "copying files to jax_flax_trainer-0.1...\n",
      "copying setup.py -> jax_flax_trainer-0.1\n",
      "copying jax_flax_trainer.egg-info/PKG-INFO -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/SOURCES.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/dependency_links.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/requires.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying jax_flax_trainer.egg-info/top_level.txt -> jax_flax_trainer-0.1/jax_flax_trainer.egg-info\n",
      "copying trainer/__init__.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/saved_model_lib_tf2_4.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task.py -> jax_flax_trainer-0.1/trainer\n",
      "copying trainer/task_tf2_4.py -> jax_flax_trainer-0.1/trainer\n",
      "Writing jax_flax_trainer-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'jax_flax_trainer-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!cd $TRAINING_APP_FOLDER && python ./setup.py sdist --formats=gztar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!gsutil -q cp $TRAINING_APP_FOLDER/dist/$MODELPACKAGE_NAME $MODELPACKAGE_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run custom training job with Python package on Vertex AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JAXLIB_URI = (\n",
    "    \"gs://jax-releases/cuda110/jaxlib-0.1.67+\"\n",
    "    \"cuda110-cp37-none-manylinux2010_x86_64.whl\"\n",
    ")\n",
    "PYTHON_PACKAGE_URIS = [f\"{MODELPACKAGE_DIR}/{MODELPACKAGE_NAME}\", JAXLIB_URI]\n",
    "PYTHON_MODULE = \"trainer.task_tf2_4\"\n",
    "\n",
    "if USE_GPU:\n",
    "    TRAINING_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest\"\n",
    "else:\n",
    "    TRAINING_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-4:latest\"\n",
    "\n",
    "python_package_spec = {\n",
    "    \"executor_image_uri\": TRAINING_IMAGE,\n",
    "    \"package_uris\": PYTHON_PACKAGE_URIS,\n",
    "    \"python_module\": PYTHON_MODULE,\n",
    "    \"args\": [\n",
    "        f\"--model_name={MODEL_NAME}\",\n",
    "        f\"--model_version={MODEL_VERSION}\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertex AI machines to use for training\n",
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "REPLICA_COUNT = 1\n",
    "\n",
    "if USE_GPU:\n",
    "    ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "    ACCELERATOR_COUNT = 1\n",
    "else:\n",
    "    ACCELERATOR_TYPE = None\n",
    "    ACCELERATOR_COUNT = None\n",
    "\n",
    "worker_pool_spec = {\n",
    "    \"machine_spec\": {\n",
    "        \"machine_type\": MACHINE_TYPE,\n",
    "        \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "        \"accelerator_count\": ACCELERATOR_COUNT,\n",
    "    },\n",
    "    \"replica_count\": REPLICA_COUNT,\n",
    "    \"python_package_spec\": python_package_spec,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = \"jax_prebuilt_training\"\n",
    "\n",
    "custom_job = {\n",
    "    \"display_name\": JOB_NAME,\n",
    "    \"job_spec\": {\n",
    "        \"worker_pool_specs\": [worker_pool_spec],\n",
    "        \"base_output_directory\": {\n",
    "            \"output_uri_prefix\": BASE_OUTPUT_DIR,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_endpoint: str = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "client_options = {\"api_endpoint\": api_endpoint}\n",
    "client = aiplatform.gapic.JobServiceClient(client_options=client_options)\n",
    "\n",
    "parent = f\"projects/{PROJECT_ID}/locations/{REGION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: name: \"projects/654544512569/locations/us-central1/customJobs/8507110580102889472\"\n",
      "display_name: \"jax_prebuilt_training\"\n",
      "job_spec {\n",
      "  worker_pool_specs {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "      accelerator_type: NVIDIA_TESLA_T4\n",
      "      accelerator_count: 1\n",
      "    }\n",
      "    replica_count: 1\n",
      "    disk_spec {\n",
      "      boot_disk_type: \"pd-ssd\"\n",
      "      boot_disk_size_gb: 100\n",
      "    }\n",
      "    python_package_spec {\n",
      "      executor_image_uri: \"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest\"\n",
      "      package_uris: \"gs://dsparing-sandbox/trainers/jax_model_prebuilt/jax_flax_trainer-0.1.tar.gz\"\n",
      "      package_uris: \"gs://jax-releases/cuda110/jaxlib-0.1.67+cuda110-cp37-none-manylinux2010_x86_64.whl\"\n",
      "      python_module: \"trainer.task_tf2_4\"\n",
      "      args: \"--model_name=jax_model_prebuilt\"\n",
      "      args: \"--model_version=1\"\n",
      "    }\n",
      "  }\n",
      "  base_output_directory {\n",
      "    output_uri_prefix: \"gs://dsparing-sandbox\"\n",
      "  }\n",
      "}\n",
      "state: JOB_STATE_PENDING\n",
      "create_time {\n",
      "  seconds: 1625150066\n",
      "  nanos: 223148000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1625150066\n",
      "  nanos: 223148000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.create_custom_job(parent=parent, custom_job=custom_job)\n",
    "print(\"response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_PENDING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job_state = client.get_custom_job(name=response.name).state\n",
    "    print(job_state)\n",
    "    if job_state not in (\n",
    "        aiplatform_v1.JobState.JOB_STATE_QUEUED,\n",
    "        aiplatform_v1.JobState.JOB_STATE_PENDING,\n",
    "        aiplatform_v1.JobState.JOB_STATE_RUNNING,\n",
    "    ):\n",
    "        break\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local prediction with SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the timestamps below that the model is newly written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  2021-06-30T04:49:45Z  gs://dsparing-sandbox/model/jax_model_prebuilt/1/\n",
      "     49753  2021-07-01T14:50:32Z  gs://dsparing-sandbox/model/jax_model_prebuilt/1/saved_model.pb\n",
      "                                 gs://dsparing-sandbox/model/jax_model_prebuilt/1/assets/\n",
      "                                 gs://dsparing-sandbox/model/jax_model_prebuilt/1/variables/\n",
      "TOTAL: 2 objects, 49753 bytes (48.59 KiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -l $BASE_OUTPUT_DIR/model/$MODEL_NAME/$MODEL_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Load dataset info from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n",
      "INFO:absl:Field info.citation from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.splits from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
      "INFO:absl:Reusing dataset mnist (/home/jupyter/tensorflow_datasets/mnist/3.0.1)\n",
      "INFO:absl:Constructing tf.data.Dataset mnist for split test, from /home/jupyter/tensorflow_datasets/mnist/3.0.1\n"
     ]
    }
   ],
   "source": [
    "# need to initialize flags somehow to avoid errors in load_mnist\n",
    "flags.FLAGS([\"\"])\n",
    "\n",
    "images_to_predict, _ = next(\n",
    "    iter(mnist_lib.load_mnist(tfds.Split.TEST, batch_size=SERVING_BATCH_SIZE))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n",
       " array([[-1.0069501e+01, -2.3111656e+01, -1.1957015e+01, -9.8489275e+00,\n",
       "         -1.8814577e+01, -1.1980792e+01, -2.1702503e+01, -4.6480820e-04,\n",
       "         -1.0392562e+01, -8.0278521e+00],\n",
       "        [-5.2159538e+00, -8.7340212e+00, -4.7790408e+00, -4.5998144e+00,\n",
       "         -4.3836346e+00, -3.2001929e+00, -6.3972487e+00, -7.1097474e+00,\n",
       "         -1.1168523e-01, -3.6531754e+00],\n",
       "        [-1.7394794e+01, -1.6356308e+01, -1.0075261e-03, -7.8558688e+00,\n",
       "         -2.2520752e+01, -1.2708941e+01, -1.6958504e+01, -2.1539352e+01,\n",
       "         -7.3916960e+00, -2.0681179e+01]], dtype=float32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(\n",
    "    f\"{BASE_OUTPUT_DIR}/model/{MODEL_NAME}/{MODEL_VERSION}\"\n",
    ")\n",
    "loaded_model.signatures[\"serving_default\"](images_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "name": "JAX Flax MNIST containerize",
   "provenance": [
    {
     "file_id": "1HenHxSnSqNQPqMPZNG_uhFampEPxN_Cj",
     "timestamp": 1617196427779
    }
   ]
  },
  "environment": {
   "name": "tf2-gpu.2-5.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
