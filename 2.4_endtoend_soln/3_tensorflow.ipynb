{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating TensorFlow model </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating a model using the high-level Estimator API \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'ryan-asl'\n",
    "PROJECT = 'billingtest-175516'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import os environment variables\n",
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make bucket if bucket doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure the training and evaluation CSVs are in the correct location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "ls *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create TensorFlow model using TensorFlow's Estimator API </h2>\n",
    "<p>\n",
    "First, write an input_fn to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import modules\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine CSV, label, and key columns\n",
    "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,mother_race,plurality,gestation_weeks,mother_married,cigarette_use,alcohol_use,key'.split(',')\n",
    "LABEL_COLUMN = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "# Set default values for each CSV column\n",
    "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], [0.0], ['null'], ['null'], ['null'], ['nokey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define some hyperparameters\n",
    "TRAIN_STEPS = 1000\n",
    "BUFFER_SIZE = 512\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_REPEAT_COUNT = 8\n",
    "EVAL_REPEAT_COUNT = 1\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_UNITS = [64, 16, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "    def decode_csv(value_column):\n",
    "      columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "      features = dict(zip(CSV_COLUMNS, columns))\n",
    "      label = features.pop(LABEL_COLUMN)\n",
    "      return features, label\n",
    "    \n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = (tf.data.TextLineDataset(file_list)  # Read text file\n",
    "                 .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
    "      \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        num_epochs = None # indefinitely\n",
    "        dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "    else:\n",
    "        num_epochs = 1 # end-of-input after this\n",
    " \n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define feature columns\n",
    "def get_wide_deep():\n",
    "  # Define column types\n",
    "  races = ['White', 'Black', 'American Indian', 'Chinese', \n",
    "           'Japanese', 'Hawaiian', 'Filipino', 'Unknown',\n",
    "           'Asian Indian', 'Korean', 'Samaon', 'Vietnamese']\n",
    "  is_male, mother_age, mother_race, plurality, gestation_weeks, mother_married, cigarette_use, alcohol_use = \\\n",
    "   [ \\\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('is_male', \n",
    "                        ['True', 'False', 'Unknown']),\n",
    "    tf.feature_column.numeric_column('mother_age'),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('mother_race', \n",
    "                        races),\n",
    "    tf.feature_column.numeric_column('plurality'),\n",
    "    tf.feature_column.numeric_column('gestation_weeks'),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('mother_married', \n",
    "                        ['True', 'False']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('cigarette_use', \n",
    "                        ['True', 'False', 'None']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('alcohol_use', \n",
    "                        ['True', 'False', 'None'])\n",
    "    ]\n",
    "\n",
    "  # Discretize/bucketize continuous features\n",
    "  mother_age_buckets = tf.feature_column.bucketized_column(mother_age, \n",
    "                        boundaries=np.arange(15, 45, 1).tolist())\n",
    "  plurality_buckets = tf.feature_column.bucketized_column(plurality, \n",
    "                        boundaries=np.arange(0.5, 5.5, 1.0).tolist())\n",
    "  gestation_buckets = tf.feature_column.bucketized_column(gestation_weeks, \n",
    "                        boundaries=np.arange(17, 47, 1).tolist())\n",
    "  \n",
    "  # Feature cross all three bucketized feature columns to create a sparse representation\n",
    "  buckets_crossed = tf.feature_column.crossed_column([mother_age_buckets, \n",
    "                                                      plurality_buckets, \n",
    "                                                      gestation_buckets], \n",
    "                                                     hash_bucket_size = 20000)\n",
    "  \n",
    "  # Embed mother race into a lower dimensional continuous space\n",
    "  mother_race_embed = tf.feature_column.embedding_column(mother_race, EMBED_SIZE)\n",
    "\n",
    "  # Sparse columns are wide, have a linear relationship with the output\n",
    "  wide = [is_male, mother_race, \n",
    "          mother_age_buckets, plurality_buckets, gestation_buckets,\n",
    "          mother_married, cigarette_use, alcohol_use, buckets_crossed]\n",
    "  \n",
    "  # Cross all wide columns and embed into a lower dimension\n",
    "  wide_crossed = tf.feature_column.crossed_column(wide, hash_bucket_size = 20000)\n",
    "  wide_embed = tf.feature_column.embedding_column(wide_crossed, EMBED_SIZE)\n",
    "\n",
    "  # Continuous columns are deep, have a complex relationship with the output\n",
    "  deep = [mother_age,\n",
    "          mother_race_embed,\n",
    "          plurality,\n",
    "          gestation_weeks,\n",
    "          wide_embed\n",
    "               ]\n",
    "  return wide, deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the TensorFlow model, we also need a serving input function. We will want all the inputs from our user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create serving input function to be able to serve predictions later using provided inputs\n",
    "def serving_input_fn():\n",
    "  feature_placeholders = {\n",
    "    'is_male': tf.placeholder(tf.string, [None]),\n",
    "    'mother_age': tf.placeholder(tf.float32, [None]),\n",
    "    'mother_race': tf.placeholder(tf.string, [None]),\n",
    "    'plurality': tf.placeholder(tf.float32, [None]),\n",
    "    'gestation_weeks': tf.placeholder(tf.float32, [None]),\n",
    "    'mother_married': tf.placeholder(tf.string, [None]),\n",
    "    'cigarette_use': tf.placeholder(tf.string, [None]),\n",
    "    'alcohol_use': tf.placeholder(tf.string, [None])\n",
    "  }\n",
    "  features = {\n",
    "    key: tf.expand_dims(tensor, -1)\n",
    "    for key, tensor in feature_placeholders.items()\n",
    "  }\n",
    "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(output_dir):\n",
    "  wide, deep = get_wide_deep()\n",
    "  estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "                       model_dir = output_dir,\n",
    "                       linear_feature_columns = wide,\n",
    "                       dnn_feature_columns = deep,\n",
    "                       dnn_hidden_units = HIDDEN_UNITS)\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "                       input_fn = read_dataset('train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = TRAIN_STEPS)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "                       input_fn = read_dataset('eval.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 60, # start evaluating after N seconds\n",
    "                       throttle_secs = 300,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd37518fd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'babyweight_trained', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 44982.938, step = 1\n",
      "INFO:tensorflow:global_step/sec: 8.60145\n",
      "INFO:tensorflow:loss = 21244.68, step = 101 (11.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.10682\n",
      "INFO:tensorflow:loss = 19450.246, step = 201 (12.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.10933\n",
      "INFO:tensorflow:loss = 18393.21, step = 301 (12.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.17456\n",
      "INFO:tensorflow:loss = 16643.086, step = 401 (12.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.10799\n",
      "INFO:tensorflow:loss = 15497.284, step = 501 (12.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.18781\n",
      "INFO:tensorflow:loss = 14978.523, step = 601 (12.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.29685\n",
      "INFO:tensorflow:loss = 13666.898, step = 701 (12.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.37052\n",
      "INFO:tensorflow:loss = 13332.431, step = 801 (11.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.43095\n",
      "INFO:tensorflow:loss = 12940.65, step = 901 (11.861 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into babyweight_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 13569.814.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-06-06:45:22\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-06-06:45:24\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 23.780355, global_step = 1000, loss = 11088.439\n",
      "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-1517899525/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate('babyweight_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it, the final lines of the output (above) were:\n",
    "<pre>\n",
    "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.1695355, global_step = 1000, loss = 37.41367\n",
    "INFO:tensorflow:Performing the final export in the end of training.\n",
    "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
    "INFO:tensorflow:Assets added to graph.\n",
    "INFO:tensorflow:No assets to write.\n",
    "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-1517330487/saved_model.pb\n",
    "</pre>\n",
    "The exporter directory contains the final model and the final RMSE (the average_loss) is 1.1695355"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitor and experiment with training </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "my_pid = TensorBoard().start('./babyweight_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorBoard, look at the learned embeddings for the race. Are they getting clustered? How about the weights for the hidden layers? What if you run this longer? What happens if you change the batchsize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TensorBoard.stop(my_pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
